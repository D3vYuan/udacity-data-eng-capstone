{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "A travel agency startup, Travellers Inc, wants to hope on to the digital transformation and transform their business with technology or TravelTech.\n",
    "\n",
    "As their data engineer, you are tasked with building an ETL pipeline that extracts data from the sources they have collected previously and transforms the data into a set of dimensional tables for the analytics team to continue finding insights into where and what attracts travellers to visit the United States.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DateType, StringType, IntegerType\n",
    "from pyspark.sql.functions import count, desc, col, when, from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "DATABASE_HOST=\"127.0.0.1\"\n",
    "DATABASE_PORT=\"5432\"\n",
    "DATABASE_NAME=\"travellers\"\n",
    "DATABASE_USER=\"<database_user>\"\n",
    "DATABASE_PASS=\"<database_pass>\"\n",
    "DATABASE_URL=f\"jdbc:postgresql://{DATABASE_HOST}:{DATABASE_PORT}/{DATABASE_NAME}\"\n",
    "DATABASE_POSTGRESQL_URL=f\"postgresql://{DATABASE_USER}:{DATABASE_PASS}@{DATABASE_HOST}:{DATABASE_PORT}/{DATABASE_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.1: Scope "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This are the data which we have on hands\n",
    "* 194 Immigration Data\n",
    "* Temperature Data \n",
    "* US Demographics Data\n",
    "* Airport Code Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "1. We may want to study how the weather affects the travelers coming into the country. <br /> \n",
    "Eg. During Summer, there are less `pleasure` travelers. During Fall or Spring, we might see more of `student` travelers. <br /> \n",
    "This would allow us to better plan and cater the air traffic resources during different period of the year. <br /> \n",
    "In addition, this data could be provided to retailers so that they can planed for events throughout the year to attract the resepctive types of travellers <br /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "2. We could also the data to study where in particular is a popular spot for travellers throughout the year. <br />\n",
    "Eg. Canada might be a hotspot for `pleasure` travelers during the autumn season <br />\n",
    "This would allow us to planned ahead for the increase in tourists so as to provide them with a more pleasant experience <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2: Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",cicid,i94yr,i94mon,i94cit,i94res,i94port,arrdate,i94mode,i94addr,depdate,i94bir,i94visa,count,dtadfile,visapost,occup,entdepa,entdepd,entdepu,matflag,biryear,dtaddto,gender,insnum,airline,admnum,fltno,visatype\n",
      "2027561,4084316.0,2016.0,4.0,209.0,209.0,HHW,20566.0,1.0,HI,20573.0,61.0,2.0,1.0,20160422,,,G,O,,M,1955.0,07202016,F,,JL,56582674633.0,00782,WT\n",
      "2171295,4422636.0,2016.0,4.0,582.0,582.0,MCA,20567.0,1.0,TX,20568.0,26.0,2.0,1.0,20160423,MTR,,G,R,,M,1990.0,10222016,M,,*GA,94361995930.0,XBLNG,B2\n",
      "589494,1195600.0,2016.0,4.0,148.0,112.0,OGG,20551.0,1.0,FL,20571.0,76.0,2.0,1.0,20160407,,,G,O,,M,1940.0,07052016,M,,LH,55780468433.0,00464,WT\n",
      "2631158,5291768.0,2016.0,4.0,297.0,297.0,LOS,20572.0,1.0,CA,20581.0,25.0,2.0,1.0,20160428,DOH,,G,O,,M,1991.0,10272016,M,,QR,94789696030.0,00739,B2\n"
     ]
    }
   ],
   "source": [
    "!head -5 ./dataset/immigration_data_sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt,AverageTemperature,AverageTemperatureUncertainty,City,Country,Latitude,Longitude\n",
      "1743-11-01,6.068,1.7369999999999999,Århus,Denmark,57.05N,10.33E\n",
      "1743-12-01,,,Århus,Denmark,57.05N,10.33E\n",
      "1744-01-01,,,Århus,Denmark,57.05N,10.33E\n",
      "1744-02-01,,,Århus,Denmark,57.05N,10.33E\n"
     ]
    }
   ],
   "source": [
    "!head -5 ../../data2/GlobalLandTemperaturesByCity.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City;State;Median Age;Male Population;Female Population;Total Population;Number of Veterans;Foreign-born;Average Household Size;State Code;Race;Count\n",
      "Silver Spring;Maryland;33.8;40601;41862;82463;1562;30908;2.6;MD;Hispanic or Latino;25924\n",
      "Quincy;Massachusetts;41.0;44129;49500;93629;4147;32935;2.39;MA;White;58723\n",
      "Hoover;Alabama;38.5;38040;46799;84839;4819;8229;2.58;AL;Asian;4759\n",
      "Rancho Cucamonga;California;34.5;88127;87105;175232;5821;33878;3.18;CA;Black or African-American;24437\n"
     ]
    }
   ],
   "source": [
    "!head -5 ./dataset/us-cities-demographics.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ident,type,name,elevation_ft,continent,iso_country,iso_region,municipality,gps_code,iata_code,local_code,coordinates\n",
      "00A,heliport,Total Rf Heliport,11,NA,US,US-PA,Bensalem,00A,,00A,\"-74.93360137939453, 40.07080078125\"\n",
      "00AA,small_airport,Aero B Ranch Airport,3435,NA,US,US-KS,Leoti,00AA,,00AA,\"-101.473911, 38.704022\"\n",
      "00AK,small_airport,Lowell Field,450,NA,US,US-AK,Anchor Point,00AK,,00AK,\"-151.695999146, 59.94919968\"\n",
      "00AL,small_airport,Epps Airpark,820,NA,US,US-AL,Harvest,00AL,,00AL,\"-86.77030181884766, 34.86479949951172\"\n"
     ]
    }
   ],
   "source": [
    "!head -5 ./dataset/airport-codes_csv.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Uitlity Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark_session = SparkSession.builder.\\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "    enableHiveSupport().getOrCreate()\n",
    "    return spark_session\n",
    "    #     config(\"spark.jars\",\"./driver/postgresql-42.4.0.jar\").\\\n",
    "#     config(\"spark.jars.packages\", \"org.postgresql:postgresql:jar:42.4.0\").\\\n",
    "# config('spark.driver.extraClassPath', './driver/postgresql-42.4.0.jar').\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def show_spark_config(spark):\n",
    "    print(spark.sparkContext.getConf().getAll())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_csv(file_path, separator=',', header='infer'):\n",
    "    if (not os.path.exists(file_path)):\n",
    "        print(f\"No data loaded - {file_path} does not exists!\")\n",
    "    return pd.read_csv(file_path, sep=separator, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_sas_files(spark_session, sas_file_pattern, sas_columns):\n",
    "    count=0\n",
    "    df_spark=None\n",
    "    \n",
    "    for sas_file_path in glob.glob(sas_file_pattern, recursive=True):\n",
    "        print(f\"{count}\")\n",
    "        file_name_without_extension=Path(sas_file_path).stem\n",
    "        sas_output_folder=f\"./sas_data/sas_data_{file_name_without_extension}\"\n",
    "        print(f\"Processing: Loading {sas_file_path} into {sas_output_folder}\")\n",
    "        df_sas = load_sas_file(spark_session, sas_file_path, sas_output_folder)\n",
    "        df_sas = df_sas.select(sas_columns)\n",
    "        total_records = df_sas.count()\n",
    "        total_columns = len(df_sas.columns)\n",
    "        print(f\"Processing: Loaded {sas_file_path} with [{total_records}] records with [{total_columns}] columns\")\n",
    "        print(df_sas.columns)\n",
    "        source_columns = 0 if df_spark is None else len(df_spark.columns)\n",
    "        if (df_spark is None):\n",
    "            print(f\"Processing: Assigning Dataset to Immigration\")\n",
    "            df_spark = df_sas\n",
    "        elif (total_columns == source_columns):\n",
    "            print(f\"Processing: Union Dataset to Immigration\")\n",
    "            df_spark = df_spark.union(df_sas)\n",
    "        else:\n",
    "            print(f\"Processing: Columns Mismatched to Immigration - has [{total_columns}] expected [{source_columns}]\")\n",
    "        print(\"--\")\n",
    "        count+=1\n",
    "    #     if (count > 0):\n",
    "    #         break\n",
    "    return df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_sas_file(spark_session, sas_file_path, sas_output_folder):\n",
    "    df_spark = spark_session.read.format('com.github.saurfang.sas.spark')\\\n",
    "        .load(sas_file_path)\n",
    "\n",
    "#     sas_output_folder=\"./sas_data\"\n",
    "    \n",
    "    sas_output_path = Path(sas_output_folder)\n",
    "#     if sas_output_path.exists():\n",
    "#         print (f\"Processing: Loading {sas_file_path} into {sas_output_path}\")\n",
    "#         shutil.rmtree(sas_output_path, ignore_errors=False, onerror=None)\n",
    "\n",
    "    #write to parquet\n",
    "    if not sas_output_path.exists():\n",
    "        df_spark.write.parquet(sas_output_folder)\n",
    "    df_spark=spark_session.read.parquet(sas_output_folder)\n",
    "    \n",
    "    return df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def describe_dataframe(df):\n",
    "    total_rows=len(df)\n",
    "    total_columns=len(df.columns)\n",
    "    print(f\"Processing: There are a total of [{total_rows}] rows\")\n",
    "    print(\"--\")\n",
    "    print(f\"Processing: The following is the available [{total_columns}] columns\")\n",
    "#     df_immigration.columns\n",
    "#     print(df.dtypes)\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"--\")\n",
    "    print(f\"Processing: The following is the available statistics of the [{total_columns}] columns\")\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def housekeep_rows_with_empty_values(df):\n",
    "    total_rows=len(df)\n",
    "    print(f\"Processing: Before removing empty rows - [{total_rows}] rows\")\n",
    "    df_non_empty=df.dropna()\n",
    "    total_rows=len(df_non_empty)\n",
    "    print(f\"Processing: After removing empty rows - [{total_rows}] rows\")\n",
    "    print(\"--\")\n",
    "    return df_non_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def housekeep_rows_with_duplicated_values(df):\n",
    "    total_rows=len(df)\n",
    "    print(f\"Processing: Before removing duplicated rows - [{total_rows}] rows\")\n",
    "    df_non_duplicate=df.drop_duplicates()\n",
    "    total_rows=len(df_non_duplicate)\n",
    "    print(f\"Processing: After removing duplicated rows - [{total_rows}] rows\")\n",
    "    print(\"--\")\n",
    "    return df_non_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def housekeep_empty_and_duplicates(df):\n",
    "    df=housekeep_rows_with_empty_values(df)\n",
    "    df=housekeep_rows_with_duplicated_values(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def replace_series_value(series, value_to_remove, value_to_replace=\"\"):\n",
    "    print(f\"Processing: Replacing Series Value [{value_to_remove}] to [{value_to_replace}]\")\n",
    "    series=series.astype(str).str.replace(\"[\"+value_to_remove+\"]\",value_to_replace,regex=True)\n",
    "    series=series.astype(str).str.strip()\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_sas_date_to_readable_format(df, sas_column_name, readable_column_name, readable_format):\n",
    "    print(f\"Processing: Converting SAS Date [{sas_column_name}] to [{readable_column_name}] with date format ({readable_format})\")\n",
    "    return df.withColumn(readable_column_name, \\\n",
    "                from_unixtime(df_immigration[sas_column_name]  * 86400 - 315619200, readable_format) if df_immigration[sas_column_name] is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_seasonality(month):\n",
    "    # April to June as Spring\n",
    "    # July to September as Summer\n",
    "    # October to December as Fall\n",
    "    # January to March as Winter\n",
    "    seasonality = {\n",
    "        \"january\": \"winter\",\n",
    "        \"february\": \"winter\",\n",
    "        \"march\": \"winter\",\n",
    "        \"april\": \"spring\",\n",
    "        \"may\": \"spring\",\n",
    "        \"june\": \"spring\",\n",
    "        \"july\": \"summer\",\n",
    "        \"august\": \"summer\",\n",
    "        \"september\": \"summer\",\n",
    "        \"october\": \"fall\",\n",
    "        \"november\": \"fall\",\n",
    "        \"december\": \"fall\"\n",
    "    }\n",
    "    \n",
    "    return seasonality.get(month.lower(), \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1: Data Exploration and Cleaning (194 Immigration Data)\n",
    "Identify data quality issues, like missing values, duplicate data, etc. <br />\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001 ./dataset/immigration_data_sample.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"./dataset/immigration_data_sample.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immigration_sample = load_csv('./dataset/immigration_data_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: There are a total of [1000] rows\n",
      "--\n",
      "Processing: The following is the available [29] columns\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 29 columns):\n",
      "Unnamed: 0    1000 non-null int64\n",
      "cicid         1000 non-null float64\n",
      "i94yr         1000 non-null float64\n",
      "i94mon        1000 non-null float64\n",
      "i94cit        1000 non-null float64\n",
      "i94res        1000 non-null float64\n",
      "i94port       1000 non-null object\n",
      "arrdate       1000 non-null float64\n",
      "i94mode       1000 non-null float64\n",
      "i94addr       941 non-null object\n",
      "depdate       951 non-null float64\n",
      "i94bir        1000 non-null float64\n",
      "i94visa       1000 non-null float64\n",
      "count         1000 non-null float64\n",
      "dtadfile      1000 non-null int64\n",
      "visapost      382 non-null object\n",
      "occup         4 non-null object\n",
      "entdepa       1000 non-null object\n",
      "entdepd       954 non-null object\n",
      "entdepu       0 non-null float64\n",
      "matflag       954 non-null object\n",
      "biryear       1000 non-null float64\n",
      "dtaddto       1000 non-null object\n",
      "gender        859 non-null object\n",
      "insnum        35 non-null float64\n",
      "airline       967 non-null object\n",
      "admnum        1000 non-null float64\n",
      "fltno         992 non-null object\n",
      "visatype      1000 non-null object\n",
      "dtypes: float64(15), int64(2), object(12)\n",
      "memory usage: 226.6+ KB\n",
      "None\n",
      "--\n",
      "Processing: The following is the available statistics of the [29] columns\n",
      "         Unnamed: 0         cicid   i94yr  i94mon       i94cit      i94res  \\\n",
      "count  1.000000e+03  1.000000e+03  1000.0  1000.0  1000.000000  1000.00000   \n",
      "mean   1.542097e+06  3.040461e+06  2016.0     4.0   302.928000   298.26200   \n",
      "std    9.152879e+05  1.799818e+06     0.0     0.0   206.485285   202.12039   \n",
      "min    1.092500e+04  1.320800e+04  2016.0     4.0   103.000000   103.00000   \n",
      "25%    7.214422e+05  1.412170e+06  2016.0     4.0   135.000000   131.00000   \n",
      "50%    1.494568e+06  2.941176e+06  2016.0     4.0   213.000000   213.00000   \n",
      "75%    2.360901e+06  4.694151e+06  2016.0     4.0   438.000000   438.00000   \n",
      "max    3.095749e+06  6.061994e+06  2016.0     4.0   746.000000   696.00000   \n",
      "\n",
      "            arrdate      i94mode       depdate       i94bir      i94visa  \\\n",
      "count   1000.000000  1000.000000    951.000000  1000.000000  1000.000000   \n",
      "mean   20559.680000     1.078000  20575.037855    42.382000     1.859000   \n",
      "std        8.995027     0.485955     24.211234    17.903424     0.386353   \n",
      "min    20545.000000     1.000000  20547.000000     1.000000     1.000000   \n",
      "25%    20552.000000     1.000000  20561.000000    30.750000     2.000000   \n",
      "50%    20560.000000     1.000000  20570.000000    42.000000     2.000000   \n",
      "75%    20567.250000     1.000000  20580.000000    55.000000     2.000000   \n",
      "max    20574.000000     9.000000  20715.000000    93.000000     3.000000   \n",
      "\n",
      "        count      dtadfile  entdepu      biryear       insnum        admnum  \n",
      "count  1000.0  1.000000e+03      0.0  1000.000000    35.000000  1.000000e+03  \n",
      "mean      1.0  2.016042e+07      NaN  1973.618000  3826.857143  6.937237e+10  \n",
      "std       0.0  4.951657e+01      NaN    17.903424   221.742583  2.338134e+10  \n",
      "min       1.0  2.016040e+07      NaN  1923.000000  3468.000000  0.000000e+00  \n",
      "25%       1.0  2.016041e+07      NaN  1961.000000  3668.000000  5.599301e+10  \n",
      "50%       1.0  2.016042e+07      NaN  1974.000000  3887.000000  5.931477e+10  \n",
      "75%       1.0  2.016042e+07      NaN  1985.250000  3943.000000  9.343623e+10  \n",
      "max       1.0  2.016080e+07      NaN  2015.000000  4686.000000  9.502151e+10  \n"
     ]
    }
   ],
   "source": [
    "describe_dataframe(df_immigration_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As the each month migration data is stored in separate file, we will have to loop through each file to extract the data and add all the extracted data to become the final dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There are more columns in `i94_jun16_sub.sas7bdat` compared to the rest or the dataset, hence we will extract the columns that are interested so that we could union all the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat into ./sas_data/sas_data_i94_apr16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat with [3096313] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Assigning Dataset to Immigration\n",
      "--\n",
      "1\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat into ./sas_data/sas_data_i94_sep16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat with [3733786] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Union Dataset to Immigration\n",
      "--\n",
      "2\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat into ./sas_data/sas_data_i94_nov16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat with [2914926] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Union Dataset to Immigration\n",
      "--\n",
      "3\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat into ./sas_data/sas_data_i94_mar16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat with [3157072] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Union Dataset to Immigration\n",
      "--\n",
      "4\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat into ./sas_data/sas_data_i94_jun16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat with [3574989] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Union Dataset to Immigration\n",
      "--\n",
      "5\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat into ./sas_data/sas_data_i94_aug16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat with [4103570] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Union Dataset to Immigration\n",
      "--\n",
      "6\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat into ./sas_data/sas_data_i94_may16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat with [3444249] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Union Dataset to Immigration\n",
      "--\n",
      "7\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat into ./sas_data/sas_data_i94_jan16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat with [2847924] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Union Dataset to Immigration\n",
      "--\n",
      "8\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat into ./sas_data/sas_data_i94_oct16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat with [3649136] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Union Dataset to Immigration\n",
      "--\n",
      "9\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat into ./sas_data/sas_data_i94_jul16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat with [4265031] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Union Dataset to Immigration\n",
      "--\n",
      "10\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat into ./sas_data/sas_data_i94_feb16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat with [2570543] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Union Dataset to Immigration\n",
      "--\n",
      "11\n",
      "Processing: Loading ../../data/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat into ./sas_data/sas_data_i94_dec16_sub\n",
      "Processing: Loaded ../../data/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat with [3432990] records with [10] columns\n",
      "['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
      "Processing: Union Dataset to Immigration\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# sas_columns = ['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline', 'admnum', 'fltno', 'visatype']\n",
    "sas_columns = ['i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94visa']\n",
    "sas_file_pattern = r'../../data/**/*.sas7bdat'\n",
    "spark = create_spark_session()\n",
    "df_immigration = load_sas_files(spark, sas_file_pattern, sas_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40790529"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.count() # 40790529"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As the `arrdate` and `deptdate` is in SAS NUmeric Format, we will need to convert them back to a more readable format such as `yyyy-MM-dd`.\n",
    "Based on finding, SAS Numeric Format seems to start on `1960-01-01` and the number represent the days from this date, hence we will convert this number to seconds and substract away 315619200 (Seconds from `1960-01-01` to `1970-01-01`) to derive the readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Converting SAS Date [arrdate] to [arrival_dt] with date format (yyyy-MM-dd)\n",
      "Processing: Converting SAS Date [arrdate] to [arrival_month] with date format (MMMMM)\n",
      "Processing: Converting SAS Date [depdate] to [departure_dt] with date format (yyyy-MM-dd)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(i94yr=2016.0, i94mon=4.0, i94cit=245.0, i94res=438.0, i94port='LOS', arrdate=20574.0, i94mode=1.0, i94addr='CA', depdate=20582.0, i94visa=1.0, arrival_dt='2016-04-30', arrival_month='April', departure_dt='2016-05-08')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration_with_dates = convert_sas_date_to_readable_format(df_immigration, \"arrdate\", \"arrival_dt\", \"yyyy-MM-dd\")\n",
    "df_immigration_with_dates = convert_sas_date_to_readable_format(df_immigration_with_dates, \"arrdate\", \"arrival_month\", \"MMMMM\")\n",
    "df_immigration_with_dates = convert_sas_date_to_readable_format(df_immigration_with_dates, \"depdate\", \"departure_dt\", \"yyyy-MM-dd\")\n",
    "df_immigration_with_dates.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_immigration_cleaned = df_immigration.withColumn(\"arrival_dt\", \\\n",
    "#     from_unixtime(df_immigration.arrdate  * 86400 - 315619200, \"yyyy-MM-dd\") if df_immigration.arrdate is not None else None)\n",
    "# df_immigration_cleaned = df_immigration.withColumn(\"arrival_month\", \\\n",
    "#     from_unixtime(df_immigration.arrdate  * 86400 - 315619200, \"MMMMM\") if df_immigration.arrdate is not None else None)\n",
    "# df_immigration_cleaned = df_immigration_cleaned.withColumn(\"departure_dt\", \\\n",
    "#     from_unixtime(df_immigration_cleaned.depdate  * 86400 - 315619200, \"yyyy-MM-dd\") if df_immigration_cleaned.depdate is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert_sas_date = udf(lambda x : pd.to_datetime(x  * 86400 - 315619200, unit = 's') if x is not None else None, DateType())\n",
    "# df_immigration_cleaned = df_immigration.withColumn(\"arrival_dt\", convert_sas_date(df_immigration.arrdate))\n",
    "# df_immigration_cleaned = df_immigration_cleaned.withColumn(\"departure_dt\", convert_sas_date(df_immigration_cleaned.depdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert_month_name = udf(lambda x : x.month_name() if x is not None else None, StringType())\n",
    "# df_immigration_cleaned = df_immigration_cleaned.withColumn(\"arrival_month\", convert_month_name(df_immigration_cleaned.arrival_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As we wanted to see what kind of travellers there are, we will be consolidating the total travellers by their travelling purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immigration_agg = df_immigration_with_dates\\\n",
    "    .groupBy(\"arrival_month\", \"i94cit\", \"i94port\", \"i94addr\")\\\n",
    "    .agg(count(col(\"*\")).alias(\"total_travellers\"),\\\n",
    "            count(when(col(\"i94visa\") == \"1.0\", True)).alias(\"business_travellers\"),\\\n",
    "            count(when(col(\"i94visa\") == \"2.0\", True)).alias(\"leisure_travellers\"),\\\n",
    "            count(when(col(\"i94visa\") == \"3.0\", True)).alias(\"student_travellers\"))\\\n",
    "    .orderBy(desc(\"total_travellers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810989"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration_agg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(arrival_month='August', i94cit=209.0, i94port='HHW', i94addr='HI', total_travellers=146523, business_travellers=911, leisure_travellers=145060, student_travellers=552)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration_agg.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_immigration_citizen.groupby('arrival_month').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import pyspark.sql.functions as F\n",
    "# df_immigration_citizen.groupBy(F.spark_partition_id()).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2: Data Exploration and Cleaning  (World Temperature Data)\n",
    "Identify data quality issues, like missing values, duplicate data, etc. <br />\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8599213 ../../data2/GlobalLandTemperaturesByCity.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"../../data2/GlobalLandTemperaturesByCity.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_world_temp = load_csv(\"../../data2/GlobalLandTemperaturesByCity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: There are a total of [8599212] rows\n",
      "--\n",
      "Processing: The following is the available [7] columns\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      "dt                               object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 459.2+ MB\n",
      "None\n",
      "--\n",
      "Processing: The following is the available statistics of the [7] columns\n",
      "       AverageTemperature  AverageTemperatureUncertainty\n",
      "count        8.235082e+06                   8.235082e+06\n",
      "mean         1.672743e+01                   1.028575e+00\n",
      "std          1.035344e+01                   1.129733e+00\n",
      "min         -4.270400e+01                   3.400000e-02\n",
      "25%          1.029900e+01                   3.370000e-01\n",
      "50%          1.883100e+01                   5.910000e-01\n",
      "75%          2.521000e+01                   1.349000e+00\n",
      "max          3.965100e+01                   1.539600e+01\n"
     ]
    }
   ],
   "source": [
    "describe_dataframe(df_world_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As we wanted to study how the season affects the travellers pattern, we would need to tag the season to the weather data based on the `month` and `day`. We will be using the dates in [US Seasonality 2022](https://www.calendarr.com/united-states/seasons-of-the-year-in-the-united-states/#:~:text=Fall%3A%20Starts%20on%20March%2020,until%20March%2020%20or%2021.) as a gauge for the start and end of each season\n",
    "* Spring: Starts on March 21, and ends on June 20 => We will set April to June as Spring\n",
    "* Summer: Starts on June 21, and ends on September 22 => We will set July to September as Summer\n",
    "* Fall: Starts on September 23, and ends on December 21 => We will set October to December as Fall\n",
    "* Winter: Starts on December 21, and ends on March 20 => We will set January to March as Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_us_temp=df_world_temp[df_world_temp['Country']==\"United States\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: There are a total of [687289] rows\n",
      "--\n",
      "Processing: The following is the available [7] columns\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 687289 entries, 47555 to 8439246\n",
      "Data columns (total 7 columns):\n",
      "dt                               687289 non-null object\n",
      "AverageTemperature               661524 non-null float64\n",
      "AverageTemperatureUncertainty    661524 non-null float64\n",
      "City                             687289 non-null object\n",
      "Country                          687289 non-null object\n",
      "Latitude                         687289 non-null object\n",
      "Longitude                        687289 non-null object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 41.9+ MB\n",
      "None\n",
      "--\n",
      "Processing: The following is the available statistics of the [7] columns\n",
      "       AverageTemperature  AverageTemperatureUncertainty\n",
      "count       661524.000000                   661524.00000\n",
      "mean            13.949335                        1.08955\n",
      "std              9.173337                        1.15068\n",
      "min            -25.163000                        0.04000\n",
      "25%              7.787000                        0.30000\n",
      "50%             14.922000                        0.52400\n",
      "75%             21.081000                        1.64600\n",
      "max             34.379000                       10.51900\n"
     ]
    }
   ],
   "source": [
    "describe_dataframe(df_us_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Before removing empty rows - [687289] rows\n",
      "Processing: After removing empty rows - [661524] rows\n",
      "--\n",
      "Processing: Before removing duplicated rows - [661524] rows\n",
      "Processing: After removing duplicated rows - [661524] rows\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "df_us_temp_wo_na=housekeep_empty_and_duplicates(df_us_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_us_temp_wo_na['dt']=pd.to_datetime(df_us_temp_wo_na['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_us_temp_wo_na['month']=df_us_temp_wo_na['dt'].dt.month\n",
    "df_us_temp_wo_na['month_name']=df_us_temp_wo_na['dt'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_us_temp_agg=df_us_temp_wo_na.groupby(['Country', 'City', 'month', 'month_name']).agg({'AverageTemperature': ['count','min','max','mean']})\n",
    "df_us_temp_agg=df_us_temp_agg.reset_index(level=['Country','City', 'month', 'month_name']) # reset multi indexed to single indexed\n",
    "df_us_temp_agg.columns = ['country', 'city', 'month', 'month_name', 'total_recordings', 'min_temperature', 'max_temperature', 'avg_temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_us_temp_agg.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As we want to check whether the season affects the travellers travelling patterns, we will tag the `month` with a corresponding `season`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_us_temp_agg['season']=df_us_temp_agg['month_name'].apply(lambda x : get_seasonality(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>month</th>\n",
       "      <th>month_name</th>\n",
       "      <th>total_recordings</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>193</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>10.145</td>\n",
       "      <td>5.310202</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>2</td>\n",
       "      <td>February</td>\n",
       "      <td>194</td>\n",
       "      <td>0.065</td>\n",
       "      <td>12.256</td>\n",
       "      <td>7.527418</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>3</td>\n",
       "      <td>March</td>\n",
       "      <td>194</td>\n",
       "      <td>6.431</td>\n",
       "      <td>17.104</td>\n",
       "      <td>12.064526</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>4</td>\n",
       "      <td>April</td>\n",
       "      <td>194</td>\n",
       "      <td>13.574</td>\n",
       "      <td>21.069</td>\n",
       "      <td>16.999969</td>\n",
       "      <td>spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>5</td>\n",
       "      <td>May</td>\n",
       "      <td>194</td>\n",
       "      <td>18.527</td>\n",
       "      <td>26.183</td>\n",
       "      <td>21.741758</td>\n",
       "      <td>spring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country     city  month month_name  total_recordings  \\\n",
       "0  United States  Abilene      1    January               193   \n",
       "1  United States  Abilene      2   February               194   \n",
       "2  United States  Abilene      3      March               194   \n",
       "3  United States  Abilene      4      April               194   \n",
       "4  United States  Abilene      5        May               194   \n",
       "\n",
       "   min_temperature  max_temperature  avg_temperature  season  \n",
       "0           -0.568           10.145         5.310202  winter  \n",
       "1            0.065           12.256         7.527418  winter  \n",
       "2            6.431           17.104        12.064526  winter  \n",
       "3           13.574           21.069        16.999969  spring  \n",
       "4           18.527           26.183        21.741758  spring  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_temp_agg.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.3: Data Exploration and Cleaning  (US City Demographic Data)\n",
    "Identify data quality issues, like missing values, duplicate data, etc. <br />\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2892 ./dataset/us-cities-demographics.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"./dataset/us-cities-demographics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demographic = load_csv(\"./dataset/us-cities-demographics.csv\", separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: There are a total of [2891] rows\n",
      "--\n",
      "Processing: The following is the available [12] columns\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n",
      "None\n",
      "--\n",
      "Processing: The following is the available statistics of the [12] columns\n",
      "        Median Age  Male Population  Female Population  Total Population  \\\n",
      "count  2891.000000     2.888000e+03       2.888000e+03      2.891000e+03   \n",
      "mean     35.494881     9.732843e+04       1.017696e+05      1.989668e+05   \n",
      "std       4.401617     2.162999e+05       2.315646e+05      4.475559e+05   \n",
      "min      22.900000     2.928100e+04       2.734800e+04      6.321500e+04   \n",
      "25%      32.800000     3.928900e+04       4.122700e+04      8.042900e+04   \n",
      "50%      35.300000     5.234100e+04       5.380900e+04      1.067820e+05   \n",
      "75%      38.000000     8.664175e+04       8.960400e+04      1.752320e+05   \n",
      "max      70.500000     4.081698e+06       4.468707e+06      8.550405e+06   \n",
      "\n",
      "       Number of Veterans  Foreign-born  Average Household Size         Count  \n",
      "count         2878.000000  2.878000e+03             2875.000000  2.891000e+03  \n",
      "mean          9367.832523  4.065360e+04                2.742543  4.896377e+04  \n",
      "std          13211.219924  1.557491e+05                0.433291  1.443856e+05  \n",
      "min            416.000000  8.610000e+02                2.000000  9.800000e+01  \n",
      "25%           3739.000000  9.224000e+03                2.430000  3.435000e+03  \n",
      "50%           5397.000000  1.882200e+04                2.650000  1.378000e+04  \n",
      "75%           9368.000000  3.397175e+04                2.950000  5.444700e+04  \n",
      "max         156961.000000  3.212500e+06                4.980000  3.835726e+06  \n"
     ]
    }
   ],
   "source": [
    "describe_dataframe(df_demographic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_demographic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "One other study we like to understand is which is the travellers favourite destination. For that, we would need to see if they prefered to travelled to populated areas or less dense area. To acheive that, we will be extracting some population information of the various cities in US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>MD</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>MA</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State State Code  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland         MD        33.8          40601.0   \n",
       "1            Quincy  Massachusetts         MA        41.0          44129.0   \n",
       "2            Hoover        Alabama         AL        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California         CA        34.5          88127.0   \n",
       "4            Newark     New Jersey         NJ        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population                       Race  Count  \n",
       "0            41862.0             82463         Hispanic or Latino  25924  \n",
       "1            49500.0             93629                      White  58723  \n",
       "2            46799.0             84839                      Asian   4759  \n",
       "3            87105.0            175232  Black or African-American  24437  \n",
       "4           143873.0            281913                      White  76402  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographic_filtered=df_demographic[['City','State', 'State Code', 'Median Age','Male Population','Female Population', 'Total Population', 'Race', 'Count']]\n",
    "df_demographic_filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# describe_dataframe(df_demographic_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_demographic_filtered[df_demographic_filtered['State Code']=='CA'].sort_values(by=['State','City'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There is one city (The Villages) where the female and male population is not populated, however as we are more interested in the total population and the resident race's in the area, we will not be dropping this rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>White</td>\n",
       "      <td>72211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City    State State Code  Median Age  Male Population  \\\n",
       "333   The Villages  Florida         FL        70.5              NaN   \n",
       "449   The Villages  Florida         FL        70.5              NaN   \n",
       "1437  The Villages  Florida         FL        70.5              NaN   \n",
       "\n",
       "      Female Population  Total Population                       Race  Count  \n",
       "333                 NaN             72590         Hispanic or Latino   1066  \n",
       "449                 NaN             72590  Black or African-American    331  \n",
       "1437                NaN             72590                      White  72211  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographic_filtered[df_demographic_filtered['Male Population'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Before removing duplicated rows - [2891] rows\n",
      "Processing: After removing duplicated rows - [2891] rows\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "df_demographic_wo_duplicates=housekeep_rows_with_duplicated_values(df_demographic_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['City', 'State', 'State Code', 'Median Age', 'Male Population',\n",
       "       'Female Population', 'Total Population', 'Race', 'Count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographic_wo_duplicates.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demographic_agg=df_demographic_wo_duplicates.groupby(['City', 'State', 'State Code', 'Median Age', 'Male Population',\n",
    "       'Female Population', 'Total Population']).agg({'Race': ['count'], 'Count':['sum']})\n",
    "df_demographic_agg=df_demographic_agg.reset_index()\n",
    "df_demographic_agg.columns=['city','state','state_code','median_age','total_male','total_female','total_population','total_race','total_race_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>median_age</th>\n",
       "      <th>total_male</th>\n",
       "      <th>total_female</th>\n",
       "      <th>total_population</th>\n",
       "      <th>total_race</th>\n",
       "      <th>total_race_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "      <td>31.3</td>\n",
       "      <td>65212.0</td>\n",
       "      <td>60664.0</td>\n",
       "      <td>125876</td>\n",
       "      <td>5</td>\n",
       "      <td>147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akron</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>OH</td>\n",
       "      <td>38.1</td>\n",
       "      <td>96886.0</td>\n",
       "      <td>100667.0</td>\n",
       "      <td>197553</td>\n",
       "      <td>5</td>\n",
       "      <td>210305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alafaya</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>33.5</td>\n",
       "      <td>39504.0</td>\n",
       "      <td>45760.0</td>\n",
       "      <td>85264</td>\n",
       "      <td>4</td>\n",
       "      <td>115476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>41.4</td>\n",
       "      <td>37747.0</td>\n",
       "      <td>40867.0</td>\n",
       "      <td>78614</td>\n",
       "      <td>5</td>\n",
       "      <td>89174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>GA</td>\n",
       "      <td>33.3</td>\n",
       "      <td>31695.0</td>\n",
       "      <td>39414.0</td>\n",
       "      <td>71109</td>\n",
       "      <td>5</td>\n",
       "      <td>73478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city       state state_code  median_age  total_male  total_female  \\\n",
       "0  Abilene       Texas         TX        31.3     65212.0       60664.0   \n",
       "1    Akron        Ohio         OH        38.1     96886.0      100667.0   \n",
       "2  Alafaya     Florida         FL        33.5     39504.0       45760.0   \n",
       "3  Alameda  California         CA        41.4     37747.0       40867.0   \n",
       "4   Albany     Georgia         GA        33.3     31695.0       39414.0   \n",
       "\n",
       "   total_population  total_race  total_race_count  \n",
       "0            125876           5            147900  \n",
       "1            197553           5            210305  \n",
       "2             85264           4            115476  \n",
       "3             78614           5             89174  \n",
       "4             71109           5             73478  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographic_agg.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.4: Data Exploration and Cleaning (Airport Code Data)\n",
    "Identify data quality issues, like missing values, duplicate data, etc. <br />\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55076 ./dataset/airport-codes_csv.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"./dataset/airport-codes_csv.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport = load_csv(\"./dataset/airport-codes_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: There are a total of [55075] rows\n",
      "--\n",
      "Processing: The following is the available [12] columns\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "elevation_ft    48069 non-null float64\n",
      "continent       27356 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n",
      "None\n",
      "--\n",
      "Processing: The following is the available statistics of the [12] columns\n",
      "       elevation_ft\n",
      "count  48069.000000\n",
      "mean    1240.789677\n",
      "std     1602.363459\n",
      "min    -1266.000000\n",
      "25%      205.000000\n",
      "50%      718.000000\n",
      "75%     1497.000000\n",
      "max    22000.000000\n"
     ]
    }
   ],
   "source": [
    "describe_dataframe(df_airport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_airport.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As we are more interested in travellers entering, we will only need those airport that are in US. With the airport information, we will then be able to see which airport is the most busiest at different period of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>03MT</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cascade Field</td>\n",
       "      <td>3580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MT</td>\n",
       "      <td>Cascade</td>\n",
       "      <td>3MT7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3MT7</td>\n",
       "      <td>-111.71748, 47.267327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>08IN</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Winona Lake Seaplane Base</td>\n",
       "      <td>812.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IN</td>\n",
       "      <td>Winona Lake</td>\n",
       "      <td>02D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02D</td>\n",
       "      <td>-85.830556, 41.223056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>09TA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lazy G Bar Ranch Airport</td>\n",
       "      <td>923.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Decatur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09T</td>\n",
       "      <td>-97.497002, 33.282101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0C7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Grandpas' Farm Mendota Airport</td>\n",
       "      <td>727.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IL</td>\n",
       "      <td>Mendota</td>\n",
       "      <td>IL22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL22</td>\n",
       "      <td>-89.132599, 41.521999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0D9</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Air Park North</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MI</td>\n",
       "      <td>Alba</td>\n",
       "      <td>MI30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MI30</td>\n",
       "      <td>-84.9587, 44.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0ID6</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Steele Memorial Heliport</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-ID</td>\n",
       "      <td>Salmon</td>\n",
       "      <td>67ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67ID</td>\n",
       "      <td>-113.891423, 45.173791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0L5</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goldfield Airport</td>\n",
       "      <td>5680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NV</td>\n",
       "      <td>Goldfield</td>\n",
       "      <td>NV50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NV50</td>\n",
       "      <td>-117.236368, 37.722751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0MI1</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Sugar Springs Airpark</td>\n",
       "      <td>940.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MI</td>\n",
       "      <td>Gladwin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5M6</td>\n",
       "      <td>-84.4375, 44.140301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0PA0</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Philadelphia Gliderport</td>\n",
       "      <td>670.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Hilltown</td>\n",
       "      <td>3PA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3PA2</td>\n",
       "      <td>-75.248125, 40.331227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0Z3</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Shannons Pond Seaplane Base</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Dillingham</td>\n",
       "      <td>AA15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA15</td>\n",
       "      <td>-158.577191, 59.058998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ident           type                            name  elevation_ft  \\\n",
       "221   03MT  small_airport                   Cascade Field        3580.0   \n",
       "501   08IN  seaplane_base       Winona Lake Seaplane Base         812.0   \n",
       "580   09TA  small_airport        Lazy G Bar Ranch Airport         923.0   \n",
       "636    0C7  small_airport  Grandpas' Farm Mendota Airport         727.0   \n",
       "693    0D9  small_airport                  Air Park North        1170.0   \n",
       "754   0ID6       heliport        Steele Memorial Heliport        4004.0   \n",
       "813    0L5  small_airport               Goldfield Airport        5680.0   \n",
       "863   0MI1  small_airport           Sugar Springs Airpark         940.0   \n",
       "1019  0PA0  small_airport         Philadelphia Gliderport         670.0   \n",
       "1195   0Z3  seaplane_base     Shannons Pond Seaplane Base          80.0   \n",
       "\n",
       "     continent iso_country iso_region municipality gps_code iata_code  \\\n",
       "221        NaN          US      US-MT      Cascade     3MT7       NaN   \n",
       "501        NaN          US      US-IN  Winona Lake      02D       NaN   \n",
       "580        NaN          US      US-TX      Decatur      NaN       NaN   \n",
       "636        NaN          US      US-IL      Mendota     IL22       NaN   \n",
       "693        NaN          US      US-MI         Alba     MI30       NaN   \n",
       "754        NaN          US      US-ID       Salmon     67ID       NaN   \n",
       "813        NaN          US      US-NV    Goldfield     NV50       NaN   \n",
       "863        NaN          US      US-MI      Gladwin      NaN       NaN   \n",
       "1019       NaN          US      US-PA     Hilltown     3PA2       NaN   \n",
       "1195       NaN          US      US-AK   Dillingham     AA15       NaN   \n",
       "\n",
       "     local_code             coordinates  \n",
       "221        3MT7   -111.71748, 47.267327  \n",
       "501         02D   -85.830556, 41.223056  \n",
       "580         09T   -97.497002, 33.282101  \n",
       "636        IL22   -89.132599, 41.521999  \n",
       "693        MI30        -84.9587, 44.958  \n",
       "754        67ID  -113.891423, 45.173791  \n",
       "813        NV50  -117.236368, 37.722751  \n",
       "863         5M6     -84.4375, 44.140301  \n",
       "1019       3PA2   -75.248125, 40.331227  \n",
       "1195       AA15  -158.577191, 59.058998  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check any rows that ident is different from local_code\n",
    "df_airport_ident_checks=df_airport[(df_airport['local_code'].notnull()) & (df_airport['local_code'] != df_airport['ident'])]\n",
    "df_airport_ident_checks.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport_filtered=df_airport[['ident', 'gps_code', 'iata_code', 'local_code', 'name', 'type', 'iso_country', 'iso_region', 'municipality',  'coordinates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_us_airport = df_airport_filtered[df_airport_filtered['iso_country']=='US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: There are a total of [22757] rows\n",
      "--\n",
      "Processing: The following is the available [10] columns\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22757 entries, 0 to 54896\n",
      "Data columns (total 10 columns):\n",
      "ident           22757 non-null object\n",
      "gps_code        20984 non-null object\n",
      "iata_code       2019 non-null object\n",
      "local_code      21236 non-null object\n",
      "name            22757 non-null object\n",
      "type            22757 non-null object\n",
      "iso_country     22757 non-null object\n",
      "iso_region      22757 non-null object\n",
      "municipality    22655 non-null object\n",
      "coordinates     22757 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 1.9+ MB\n",
      "None\n",
      "--\n",
      "Processing: The following is the available statistics of the [10] columns\n",
      "        ident gps_code iata_code local_code                        name  \\\n",
      "count   22757    20984      2019      21236                       22757   \n",
      "unique  22757    20932      2014      21170                       21245   \n",
      "top      ID00     14LA       AUS        6X8  Memorial Hospital Heliport   \n",
      "freq        1        2         2          2                          18   \n",
      "\n",
      "                 type iso_country iso_region municipality coordinates  \n",
      "count           22757       22757      22757        22655       22757  \n",
      "unique              7           1         52         8738       22743  \n",
      "top     small_airport          US      US-TX      Houston        0, 0  \n",
      "freq            13720       22757       2277          119           5  \n"
     ]
    }
   ],
   "source": [
    "describe_dataframe(df_us_airport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>15SD</td>\n",
       "      <td>15SD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Watertown / Brownlee Heliport</td>\n",
       "      <td>heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-SD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-97.1080899239, 44.883264878199995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>21ID</td>\n",
       "      <td>21ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nordman / Phillabaum Heliport</td>\n",
       "      <td>heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-116.871174574, 48.631483378700004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>3ME7</td>\n",
       "      <td>3ME7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru / Destiny Cove SPB</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>US</td>\n",
       "      <td>US-ME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70.396957, 44.460597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7653</th>\n",
       "      <td>6XA4</td>\n",
       "      <td>6XA4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zadow Airstrip</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-95.954353809, 29.991738550900003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7887</th>\n",
       "      <td>74xa</td>\n",
       "      <td>74XA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gun Barrel City Airpark</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-96.1456650496, 32.3551499558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8082</th>\n",
       "      <td>79ID</td>\n",
       "      <td>79ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kooskia (Clear Creek Int) Airport</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-115.869691372, 46.0488642914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>79WT</td>\n",
       "      <td>79WT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ellensburg (Rotor Ranch) Airport</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-120.589778423, 47.091426059499994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055</th>\n",
       "      <td>8FA4</td>\n",
       "      <td>8FA4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samsula / Coe Field</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-81.1328315735, 29.0102045831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9855</th>\n",
       "      <td>99XA</td>\n",
       "      <td>99XA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Briggs / Skotz Airfield</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-98.0037117004, 30.863976076700002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11676</th>\n",
       "      <td>AUS</td>\n",
       "      <td>KAUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Austin Robert Mueller Municipal</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-97.6997852325, 30.2987223546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15011</th>\n",
       "      <td>CLG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coalinga Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-120.360116959, 36.1580433385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16805</th>\n",
       "      <td>D22</td>\n",
       "      <td>D22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drummond Island / Yacht Haven SPB</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-83.752513, 46.024794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25272</th>\n",
       "      <td>K1C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1C2</td>\n",
       "      <td>Howell New Lenox Airport</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.92130279541016, 41.479801177978516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26156</th>\n",
       "      <td>KAYE</td>\n",
       "      <td>KAYE</td>\n",
       "      <td>AYE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ft Devens Moore Army Air Field</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.60279846191406, 42.56999969482422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26188</th>\n",
       "      <td>KBDX</td>\n",
       "      <td>KBDX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BDX</td>\n",
       "      <td>Broadus Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-105.416999817, 45.4333000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27485</th>\n",
       "      <td>KHMJ</td>\n",
       "      <td>KHMJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Homer Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.95249938964844, 40.02640151977539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27540</th>\n",
       "      <td>KHWC</td>\n",
       "      <td>KHWC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HWC</td>\n",
       "      <td>Bryan Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.55670166015625, 41.473899841308594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28074</th>\n",
       "      <td>KMLK</td>\n",
       "      <td>KMLK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Malta Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-107.88600158691406, 48.34939956665039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28116</th>\n",
       "      <td>KMQT</td>\n",
       "      <td>KMQT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marquette Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.5614013671875, 46.53390121459961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28127</th>\n",
       "      <td>KMSA</td>\n",
       "      <td>KMSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mt Pleasant Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-94.97560119628906, 33.129398345947266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28144</th>\n",
       "      <td>KMUF</td>\n",
       "      <td>KMUF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pikeville-Bledsoe Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85.19080352783203, 35.619998931884766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28149</th>\n",
       "      <td>KMUU</td>\n",
       "      <td>KMUU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Huntingdon County Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-77.862478, 40.329182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28253</th>\n",
       "      <td>KNQB</td>\n",
       "      <td>KNQB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KNQB</td>\n",
       "      <td>Silverhill Nolf Airport</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.80970001220703, 30.563600540161133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28281</th>\n",
       "      <td>KNZW</td>\n",
       "      <td>KNZW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NZW</td>\n",
       "      <td>South Weymouth Naval Air Station</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70.93939971923828, 42.14860153198242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28410</th>\n",
       "      <td>KOVK</td>\n",
       "      <td>KOVK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVK</td>\n",
       "      <td>Dunkirk Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.34719848632812, 42.47439956665039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28548</th>\n",
       "      <td>KPCU</td>\n",
       "      <td>KPCU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PCU</td>\n",
       "      <td>Picayune Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-89.70690155029297, 30.522499084472656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28633</th>\n",
       "      <td>KPRS</td>\n",
       "      <td>KPRS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRS</td>\n",
       "      <td>Presidio Lely International Airport</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-104.361493, 29.634212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29754</th>\n",
       "      <td>KRCP</td>\n",
       "      <td>KRCP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stockton / Rooks County Regional</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-99.304649, 39.346592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29777</th>\n",
       "      <td>KRIE</td>\n",
       "      <td>KRIE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rice Lake Airport</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-WI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.72219848632812, 45.478599548339844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30243</th>\n",
       "      <td>KUIZ</td>\n",
       "      <td>KUIZ</td>\n",
       "      <td>UIZ</td>\n",
       "      <td>UIZ</td>\n",
       "      <td>Berz-Macomb Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82.96540069580078, 42.66389846801758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49274</th>\n",
       "      <td>US-0260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Clemente Naval Auxiliary Air Station</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-118.53085, 32.94721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49275</th>\n",
       "      <td>US-0261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matagorda Peninsula Airport</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-96.1208, 28.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49279</th>\n",
       "      <td>US-0265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tiki Island</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-94.656379, 29.451407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49282</th>\n",
       "      <td>US-0268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gardiners Island Landing Field</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-72.092156, 41.065218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49283</th>\n",
       "      <td>US-0269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cedar Creek Park Aerdorome</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.506528, 40.644907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49287</th>\n",
       "      <td>US-0273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAS Squantum</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.03371, 42.29772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49299</th>\n",
       "      <td>US-0285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private strip nr Huntsville</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-95.54221, 30.79851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49300</th>\n",
       "      <td>US-0286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hodges Airfield</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-LA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-93.395117, 31.373602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49301</th>\n",
       "      <td>US-0287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest service strip nr Kurthwood, LA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-LA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-93.15745, 31.31646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49318</th>\n",
       "      <td>US-0303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>atl</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.375, 33.137551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49550</th>\n",
       "      <td>US-0535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sandy River Federal I Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-160.230109, 56.226756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49551</th>\n",
       "      <td>US-0536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>David River Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-161.638059, 55.913896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49552</th>\n",
       "      <td>US-0537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wide Bay Airport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-156.41851, 57.3717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49625</th>\n",
       "      <td>US-0610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Erase Me 13</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0, 0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49682</th>\n",
       "      <td>US-0667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Erase Me 17</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5, 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49707</th>\n",
       "      <td>US-0692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Erase Me 14</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4, 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49757</th>\n",
       "      <td>US-0742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34S Airport</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.875, 19.145168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49778</th>\n",
       "      <td>US-0763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Kohala Fire Station Helipad</td>\n",
       "      <td>heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-HI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-155.834506, 19.946485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49779</th>\n",
       "      <td>US-0764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waikoloa Air Strip</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-HI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-155.863337, 19.918787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49807</th>\n",
       "      <td>US-0792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not anywhere near Oklahoma city</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7, 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49809</th>\n",
       "      <td>US-0794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Allentown unless they moved it to the midd...</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8, 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49811</th>\n",
       "      <td>US-0796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not DTW although Detroit can be just as isolated</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8, 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49893</th>\n",
       "      <td>US-0878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy Generic Cytotec Online Without A Prescript...</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3, 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49894</th>\n",
       "      <td>US-0879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy Lyrica online (Pregabalin) 150mg capsules ...</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.1666666666667, -1.1666666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49895</th>\n",
       "      <td>US-0880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy Lyrica online. Discount Lyrica 75 mg onlin...</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.1666666666667, -2.1666666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>US-0984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0c2</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0, 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50049</th>\n",
       "      <td>US-1033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Donovan Airstrip</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-113.272078, 44.926931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50050</th>\n",
       "      <td>US-1034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hirschy Landing Strip</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-113.435281, 45.438041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50130</th>\n",
       "      <td>US-CO22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO22</td>\n",
       "      <td>Greenhorn Valley Airport</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-104.783996582, 37.959701538100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52342</th>\n",
       "      <td>WT21</td>\n",
       "      <td>WT21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deer Park / Radial Flyer Airport</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-117.439807, 47.894536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ident gps_code iata_code local_code  \\\n",
       "1544      15SD     15SD       NaN        NaN   \n",
       "2452      21ID     21ID       NaN        NaN   \n",
       "4401      3ME7     3ME7       NaN        NaN   \n",
       "7653      6XA4     6XA4       NaN        NaN   \n",
       "7887      74xa     74XA       NaN        NaN   \n",
       "8082      79ID     79ID       NaN        NaN   \n",
       "8114      79WT     79WT       NaN        NaN   \n",
       "9055      8FA4     8FA4       NaN        NaN   \n",
       "9855      99XA     99XA       NaN        NaN   \n",
       "11676      AUS     KAUS       AUS        NaN   \n",
       "15011      CLG      NaN       CLG        NaN   \n",
       "16805      D22      D22       NaN        NaN   \n",
       "25272     K1C2      NaN       NaN        1C2   \n",
       "26156     KAYE     KAYE       AYE        NaN   \n",
       "26188     KBDX     KBDX       NaN        BDX   \n",
       "27485     KHMJ     KHMJ       NaN        NaN   \n",
       "27540     KHWC     KHWC       NaN        HWC   \n",
       "28074     KMLK     KMLK       NaN        NaN   \n",
       "28116     KMQT     KMQT       NaN        NaN   \n",
       "28127     KMSA     KMSA       NaN        NaN   \n",
       "28144     KMUF     KMUF       NaN        NaN   \n",
       "28149     KMUU     KMUU       NaN        NaN   \n",
       "28253     KNQB     KNQB       NaN       KNQB   \n",
       "28281     KNZW     KNZW       NaN        NZW   \n",
       "28410     KOVK     KOVK       NaN        OVK   \n",
       "28548     KPCU     KPCU       NaN        PCU   \n",
       "28633     KPRS     KPRS       NaN        PRS   \n",
       "29754     KRCP     KRCP       NaN        NaN   \n",
       "29777     KRIE     KRIE       NaN        NaN   \n",
       "30243     KUIZ     KUIZ       UIZ        UIZ   \n",
       "...        ...      ...       ...        ...   \n",
       "49274  US-0260      NaN       NaN        NaN   \n",
       "49275  US-0261      NaN       NaN        NaN   \n",
       "49279  US-0265      NaN       NaN        NaN   \n",
       "49282  US-0268      NaN       NaN        NaN   \n",
       "49283  US-0269      NaN       NaN        NaN   \n",
       "49287  US-0273      NaN       NaN        NaN   \n",
       "49299  US-0285      NaN       NaN        NaN   \n",
       "49300  US-0286      NaN       NaN        NaN   \n",
       "49301  US-0287      NaN       NaN        NaN   \n",
       "49318  US-0303      NaN       NaN        NaN   \n",
       "49550  US-0535      NaN       NaN        NaN   \n",
       "49551  US-0536      NaN       NaN        NaN   \n",
       "49552  US-0537      NaN       NaN        NaN   \n",
       "49625  US-0610      NaN       NaN        NaN   \n",
       "49682  US-0667      NaN       NaN        NaN   \n",
       "49707  US-0692      NaN       NaN        NaN   \n",
       "49757  US-0742      NaN       NaN        NaN   \n",
       "49778  US-0763      NaN       NaN        NaN   \n",
       "49779  US-0764      NaN       NaN        NaN   \n",
       "49807  US-0792      NaN       NaN        NaN   \n",
       "49809  US-0794      NaN       NaN        NaN   \n",
       "49811  US-0796      NaN       NaN        NaN   \n",
       "49893  US-0878      NaN       NaN        NaN   \n",
       "49894  US-0879      NaN       NaN        NaN   \n",
       "49895  US-0880      NaN       NaN        NaN   \n",
       "49999  US-0984      NaN       NaN        NaN   \n",
       "50049  US-1033      NaN       NaN        NaN   \n",
       "50050  US-1034      NaN       NaN        NaN   \n",
       "50130  US-CO22      NaN       NaN       CO22   \n",
       "52342     WT21     WT21       NaN        NaN   \n",
       "\n",
       "                                                    name            type  \\\n",
       "1544                       Watertown / Brownlee Heliport        heliport   \n",
       "2452                       Nordman / Phillabaum Heliport        heliport   \n",
       "4401                             Peru / Destiny Cove SPB   seaplane_base   \n",
       "7653                                      Zadow Airstrip   small_airport   \n",
       "7887                             Gun Barrel City Airpark   small_airport   \n",
       "8082                   Kooskia (Clear Creek Int) Airport   small_airport   \n",
       "8114                    Ellensburg (Rotor Ranch) Airport   small_airport   \n",
       "9055                                 Samsula / Coe Field   small_airport   \n",
       "9855                             Briggs / Skotz Airfield   small_airport   \n",
       "11676                    Austin Robert Mueller Municipal          closed   \n",
       "15011                                   Coalinga Airport          closed   \n",
       "16805                  Drummond Island / Yacht Haven SPB   seaplane_base   \n",
       "25272                           Howell New Lenox Airport   small_airport   \n",
       "26156                     Ft Devens Moore Army Air Field          closed   \n",
       "26188                                    Broadus Airport          closed   \n",
       "27485                                      Homer Airport          closed   \n",
       "27540                                      Bryan Airport          closed   \n",
       "28074                                      Malta Airport          closed   \n",
       "28116                                  Marquette Airport          closed   \n",
       "28127                                Mt Pleasant Airport          closed   \n",
       "28144                          Pikeville-Bledsoe Airport          closed   \n",
       "28149                          Huntingdon County Airport          closed   \n",
       "28253                            Silverhill Nolf Airport   small_airport   \n",
       "28281                   South Weymouth Naval Air Station          closed   \n",
       "28410                                    Dunkirk Airport          closed   \n",
       "28548                                   Picayune Airport          closed   \n",
       "28633                Presidio Lely International Airport   small_airport   \n",
       "29754                   Stockton / Rooks County Regional   small_airport   \n",
       "29777                                  Rice Lake Airport   small_airport   \n",
       "30243                                Berz-Macomb Airport          closed   \n",
       "...                                                  ...             ...   \n",
       "49274           San Clemente Naval Auxiliary Air Station          closed   \n",
       "49275                        Matagorda Peninsula Airport   small_airport   \n",
       "49279                                        Tiki Island   small_airport   \n",
       "49282                     Gardiners Island Landing Field   small_airport   \n",
       "49283                         Cedar Creek Park Aerdorome          closed   \n",
       "49287                                       NAS Squantum          closed   \n",
       "49299                        Private strip nr Huntsville   small_airport   \n",
       "49300                                    Hodges Airfield   small_airport   \n",
       "49301              Forest service strip nr Kurthwood, LA   small_airport   \n",
       "49318                                                atl   large_airport   \n",
       "49550                      Sandy River Federal I Airport          closed   \n",
       "49551                                David River Airport          closed   \n",
       "49552                                   Wide Bay Airport          closed   \n",
       "49625                                        Erase Me 13          closed   \n",
       "49682                                        Erase Me 17          closed   \n",
       "49707                                        Erase Me 14          closed   \n",
       "49757                                        34S Airport  medium_airport   \n",
       "49778                  South Kohala Fire Station Helipad        heliport   \n",
       "49779                                 Waikoloa Air Strip          closed   \n",
       "49807                    Not anywhere near Oklahoma city          closed   \n",
       "49809  Not Allentown unless they moved it to the midd...          closed   \n",
       "49811   Not DTW although Detroit can be just as isolated          closed   \n",
       "49893  Buy Generic Cytotec Online Without A Prescript...   small_airport   \n",
       "49894  Buy Lyrica online (Pregabalin) 150mg capsules ...  medium_airport   \n",
       "49895  Buy Lyrica online. Discount Lyrica 75 mg onlin...  medium_airport   \n",
       "49999                                                0c2   small_airport   \n",
       "50049                                   Donovan Airstrip          closed   \n",
       "50050                              Hirschy Landing Strip          closed   \n",
       "50130                           Greenhorn Valley Airport   small_airport   \n",
       "52342                   Deer Park / Radial Flyer Airport   small_airport   \n",
       "\n",
       "      iso_country iso_region municipality  \\\n",
       "1544           US      US-SD          NaN   \n",
       "2452           US      US-ID          NaN   \n",
       "4401           US      US-ME          NaN   \n",
       "7653           US      US-TX          NaN   \n",
       "7887           US      US-TX          NaN   \n",
       "8082           US      US-ID          NaN   \n",
       "8114           US      US-WA          NaN   \n",
       "9055           US      US-FL          NaN   \n",
       "9855           US      US-TX          NaN   \n",
       "11676          US      US-TX          NaN   \n",
       "15011          US      US-CA          NaN   \n",
       "16805          US      US-MI          NaN   \n",
       "25272          US      US-IL          NaN   \n",
       "26156          US      US-MA          NaN   \n",
       "26188          US      US-MT          NaN   \n",
       "27485          US      US-IL          NaN   \n",
       "27540          US      US-OH          NaN   \n",
       "28074          US      US-MT          NaN   \n",
       "28116          US      US-MI          NaN   \n",
       "28127          US      US-TX          NaN   \n",
       "28144          US      US-KY          NaN   \n",
       "28149          US      US-PA          NaN   \n",
       "28253          US      US-AL          NaN   \n",
       "28281          US      US-MA          NaN   \n",
       "28410          US      US-NY          NaN   \n",
       "28548          US      US-MS          NaN   \n",
       "28633          US      US-TX          NaN   \n",
       "29754          US      US-KS          NaN   \n",
       "29777          US      US-WI          NaN   \n",
       "30243          US      US-MI          NaN   \n",
       "...           ...        ...          ...   \n",
       "49274          US      US-CA          NaN   \n",
       "49275          US      US-TX          NaN   \n",
       "49279          US      US-TX          NaN   \n",
       "49282          US      US-NY          NaN   \n",
       "49283          US      US-NY          NaN   \n",
       "49287          US      US-MA          NaN   \n",
       "49299          US      US-TX          NaN   \n",
       "49300          US      US-LA          NaN   \n",
       "49301          US      US-LA          NaN   \n",
       "49318          US     US-U-A          NaN   \n",
       "49550          US      US-AK          NaN   \n",
       "49551          US      US-AK          NaN   \n",
       "49552          US      US-AK          NaN   \n",
       "49625          US     US-U-A          NaN   \n",
       "49682          US      US-PA          NaN   \n",
       "49707          US      US-GA          NaN   \n",
       "49757          US     US-U-A          NaN   \n",
       "49778          US      US-HI          NaN   \n",
       "49779          US      US-HI          NaN   \n",
       "49807          US      US-OK          NaN   \n",
       "49809          US      US-PA          NaN   \n",
       "49811          US     US-U-A          NaN   \n",
       "49893          US      US-NY          NaN   \n",
       "49894          US     US-U-A          NaN   \n",
       "49895          US     US-U-A          NaN   \n",
       "49999          US      US-IL          NaN   \n",
       "50049          US      US-MT          NaN   \n",
       "50050          US      US-MT          NaN   \n",
       "50130          US      US-CO          NaN   \n",
       "52342          US      US-WA          NaN   \n",
       "\n",
       "                                  coordinates  \n",
       "1544       -97.1080899239, 44.883264878199995  \n",
       "2452       -116.871174574, 48.631483378700004  \n",
       "4401                    -70.396957, 44.460597  \n",
       "7653        -95.954353809, 29.991738550900003  \n",
       "7887            -96.1456650496, 32.3551499558  \n",
       "8082            -115.869691372, 46.0488642914  \n",
       "8114       -120.589778423, 47.091426059499994  \n",
       "9055            -81.1328315735, 29.0102045831  \n",
       "9855       -98.0037117004, 30.863976076700002  \n",
       "11676           -97.6997852325, 30.2987223546  \n",
       "15011           -120.360116959, 36.1580433385  \n",
       "16805                   -83.752513, 46.024794  \n",
       "25272  -87.92130279541016, 41.479801177978516  \n",
       "26156   -71.60279846191406, 42.56999969482422  \n",
       "26188           -105.416999817, 45.4333000183  \n",
       "27485   -87.95249938964844, 40.02640151977539  \n",
       "27540  -84.55670166015625, 41.473899841308594  \n",
       "28074  -107.88600158691406, 48.34939956665039  \n",
       "28116    -87.5614013671875, 46.53390121459961  \n",
       "28127  -94.97560119628906, 33.129398345947266  \n",
       "28144  -85.19080352783203, 35.619998931884766  \n",
       "28149                   -77.862478, 40.329182  \n",
       "28253  -87.80970001220703, 30.563600540161133  \n",
       "28281   -70.93939971923828, 42.14860153198242  \n",
       "28410   -79.34719848632812, 42.47439956665039  \n",
       "28548  -89.70690155029297, 30.522499084472656  \n",
       "28633                  -104.361493, 29.634212  \n",
       "29754                   -99.304649, 39.346592  \n",
       "29777  -91.72219848632812, 45.478599548339844  \n",
       "30243   -82.96540069580078, 42.66389846801758  \n",
       "...                                       ...  \n",
       "49274                    -118.53085, 32.94721  \n",
       "49275                        -96.1208, 28.544  \n",
       "49279                   -94.656379, 29.451407  \n",
       "49282                   -72.092156, 41.065218  \n",
       "49283                   -73.506528, 40.644907  \n",
       "49287                     -71.03371, 42.29772  \n",
       "49299                     -95.54221, 30.79851  \n",
       "49300                   -93.395117, 31.373602  \n",
       "49301                     -93.15745, 31.31646  \n",
       "49318                      -84.375, 33.137551  \n",
       "49550                  -160.230109, 56.226756  \n",
       "49551                  -161.638059, 55.913896  \n",
       "49552                     -156.41851, 57.3717  \n",
       "49625                                  0, 0.4  \n",
       "49682                                 -0.5, 0  \n",
       "49707                                  0.4, 0  \n",
       "49757                      -16.875, 19.145168  \n",
       "49778                  -155.834506, 19.946485  \n",
       "49779                  -155.863337, 19.918787  \n",
       "49807                                0.7, 0.5  \n",
       "49809                                0.8, 0.7  \n",
       "49811                                0.8, 0.6  \n",
       "49893                                    3, 1  \n",
       "49894       3.1666666666667, -1.1666666666667  \n",
       "49895      -2.1666666666667, -2.1666666666667  \n",
       "49999                                    0, 0  \n",
       "50049                  -113.272078, 44.926931  \n",
       "50050                  -113.435281, 45.438041  \n",
       "50130      -104.783996582, 37.959701538100006  \n",
       "52342                  -117.439807, 47.894536  \n",
       "\n",
       "[102 rows x 10 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_airport[df_us_airport['municipality'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Removing Airports with `iso_region` with value `US-U-A` as the airport name doesn't seems quite right and there is no state that is `U-A`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_us_airport_filtered=df_us_airport[df_us_airport['iso_region']!='US-U-A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_us_airport_filtered['state']=df_us_airport_filtered['iso_region'].apply(lambda x : '-'.join(x.split('-')[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AK     829\n",
       "AL     361\n",
       "AR     406\n",
       "AZ     359\n",
       "CA    1088\n",
       "CO     505\n",
       "CT     164\n",
       "DC      21\n",
       "DE      57\n",
       "FL     967\n",
       "GA     522\n",
       "HI      64\n",
       "IA     338\n",
       "ID     315\n",
       "IL     902\n",
       "IN     697\n",
       "KS     439\n",
       "KY     257\n",
       "LA     592\n",
       "MA     257\n",
       "MD     257\n",
       "ME     208\n",
       "MI     549\n",
       "MN     569\n",
       "MO     578\n",
       "MS     281\n",
       "MT     331\n",
       "NC     473\n",
       "ND     321\n",
       "NE     309\n",
       "NH     179\n",
       "NJ     442\n",
       "NM     198\n",
       "NV     156\n",
       "NY     668\n",
       "OH     799\n",
       "OK     537\n",
       "OR     492\n",
       "PA     918\n",
       "RI      35\n",
       "SC     217\n",
       "SD     211\n",
       "TN     356\n",
       "TX    2277\n",
       "UT     170\n",
       "VA     505\n",
       "VT     102\n",
       "WA     578\n",
       "WI     624\n",
       "WV     140\n",
       "WY     127\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_airport_filtered['state'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Splitting `coordinates` data as it is comma separated, and by right database should stored each data in a column for ease of query and retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_us_airport_filtered['coordinates_x']=df_us_airport_filtered['coordinates'].apply(lambda x : x.split(',')[0])\n",
    "df_us_airport_filtered['coordinates_y']=df_us_airport_filtered['coordinates'].apply(lambda x : x.split(',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_us_airport_filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ident', 'gps_code', 'iata_code', 'local_code', 'name', 'type',\n",
       "       'iso_country', 'iso_region', 'municipality', 'coordinates', 'state',\n",
       "       'coordinates_x', 'coordinates_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_airport_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>coordinates_x</th>\n",
       "      <th>coordinates_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>-74.93360137939453</td>\n",
       "      <td>40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>-101.473911</td>\n",
       "      <td>38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>-151.695999146</td>\n",
       "      <td>59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>US</td>\n",
       "      <td>AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>-86.77030181884766</td>\n",
       "      <td>34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>closed</td>\n",
       "      <td>US</td>\n",
       "      <td>AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>-91.254898</td>\n",
       "      <td>35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id gps_code iata_code local_code                                name  \\\n",
       "0   00A      00A       NaN        00A                   Total Rf Heliport   \n",
       "1  00AA     00AA       NaN       00AA                Aero B Ranch Airport   \n",
       "2  00AK     00AK       NaN       00AK                        Lowell Field   \n",
       "3  00AL     00AL       NaN       00AL                        Epps Airpark   \n",
       "4  00AR      NaN       NaN        NaN  Newport Hospital & Clinic Heliport   \n",
       "\n",
       "            type country state          city       coordinates_x  \\\n",
       "0       heliport      US    PA      Bensalem  -74.93360137939453   \n",
       "1  small_airport      US    KS         Leoti         -101.473911   \n",
       "2  small_airport      US    AK  Anchor Point      -151.695999146   \n",
       "3  small_airport      US    AL       Harvest  -86.77030181884766   \n",
       "4         closed      US    AR       Newport          -91.254898   \n",
       "\n",
       "        coordinates_y  \n",
       "0      40.07080078125  \n",
       "1           38.704022  \n",
       "2         59.94919968  \n",
       "3   34.86479949951172  \n",
       "4             35.6087  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_airport_agg = df_us_airport_filtered[['ident', 'gps_code', 'iata_code', 'local_code', 'name', 'type', 'iso_country', 'state', 'municipality', 'coordinates_x', 'coordinates_y']]\n",
    "df_us_airport_agg.columns=['id', 'gps_code', 'iata_code', 'local_code', 'name', 'type', 'country', 'state', 'city', 'coordinates_x', 'coordinates_y']\n",
    "df_us_airport_agg.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.5: Data Exploration and Cleaning (SAS Data Label)\n",
    "Identify data quality issues, like missing values, duplicate data, etc. <br />\n",
    "Document steps necessary to clean the data <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Based on the `194_SAS_Labels_Descriptions.SAS`, addtional data is extracted to complement the immigration data\n",
    "* `i94cntyl_traveller_country.map` - This is mapping file for the fields `I94CIT` and `I94RES`\n",
    "* `i94prtl_arrival_airport_city.map` - This is mapping file for the fields `I94PORT`\n",
    "* `i94model_mode_of_transport.map` - This is mapping file for the fields `I94MODE`\n",
    "* `i94addrl_arrival_airport_state.map` - This is mapping file for the fields `I94ADDR`\n",
    "* `i94visa_travelling_purpose.map` - This is mapping file for the fields `I94VISA`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.5.1: Data Exploration and Cleaning (Traveller Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 ./dataset/i94cntyl_traveller_country.map\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"./dataset/i94cntyl_traveller_country.map\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Replacing Series Value ['] to []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_code                                       country_name\n",
       "0           582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1           236                                        AFGHANISTAN\n",
       "2           101                                            ALBANIA\n",
       "3           316                                            ALGERIA\n",
       "4           102                                            ANDORRA"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traveller_country=load_csv('./dataset/i94cntyl_traveller_country.map', separator='=', header=None)\n",
    "df_traveller_country.columns=['country_code','country_name']\n",
    "df_traveller_country['country_name']=replace_series_value(df_traveller_country['country_name'], \"'\")\n",
    "df_traveller_country.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.5.2: Data Exploration and Cleaning (Arrival Airport City)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659 ./dataset/i94prtl_arrival_airport_city.map\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"./dataset/i94prtl_arrival_airport_city.map\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Replacing Series Value ['|\t] to []\n",
      "Processing: Replacing Series Value ['|\t] to []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>city_name_with_state</th>\n",
       "      <th>city_name</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN, AK</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE, AK</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND, AK</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE, AK</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW, AK</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_code          city_name_with_state                 city_name state_code\n",
       "0       ALC                     ALCAN, AK                     ALCAN         AK\n",
       "1       ANC                 ANCHORAGE, AK                 ANCHORAGE         AK\n",
       "2       BAR  BAKER AAF - BAKER ISLAND, AK  BAKER AAF - BAKER ISLAND         AK\n",
       "3       DAC             DALTONS CACHE, AK             DALTONS CACHE         AK\n",
       "4       PIZ    DEW STATION PT LAY DEW, AK    DEW STATION PT LAY DEW         AK"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_city=load_csv('./dataset/i94prtl_arrival_airport_city.map', separator='=', header=None)\n",
    "df_airport_city.columns=['city_code','city_name_with_state']\n",
    "df_airport_city['city_code']=replace_series_value(df_airport_city['city_code'], \"'|\\t\")\n",
    "df_airport_city['city_name_with_state']=replace_series_value(df_airport_city['city_name_with_state'], \"'|\\t\")\n",
    "df_airport_city['city_name']=df_airport_city['city_name_with_state'].apply(lambda x : x.split(',')[0])\n",
    "df_airport_city['state_code']=df_airport_city['city_name_with_state'].apply(lambda x : x.split(',')[-1])\n",
    "df_airport_city.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.5.3: Data Exploration and Cleaning (Mode of Transport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ./dataset/i94model_mode_of_transport.map\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"./dataset/i94model_mode_of_transport.map\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Replacing Series Value ['|\t] to []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode_code</th>\n",
       "      <th>mode_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mode_code     mode_name\n",
       "0          1           Air\n",
       "1          2           Sea\n",
       "2          3          Land\n",
       "3          9  Not reported"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mode=load_csv('./dataset/i94model_mode_of_transport.map', separator='=', header=None)\n",
    "df_mode.columns=['mode_code','mode_name']\n",
    "df_mode['mode_name']=replace_series_value(df_mode['mode_name'], \"'|\\t\")\n",
    "df_mode.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.5.4: Data Exploration and Cleaning (Arrival Airport State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 ./dataset/i94addrl_arrival_airport_state.map\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"./dataset/i94addrl_arrival_airport_state.map\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Replacing Series Value ['|\t] to []\n",
      "Processing: Replacing Series Value ['|\t] to []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  state_name\n",
       "0         AL     ALABAMA\n",
       "1         AK      ALASKA\n",
       "2         AZ     ARIZONA\n",
       "3         AR    ARKANSAS\n",
       "4         CA  CALIFORNIA"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_state=load_csv('./dataset/i94addrl_arrival_airport_state.map', separator='=', header=None)\n",
    "df_airport_state.columns=['state_code','state_name']\n",
    "df_airport_state['state_code']=replace_series_value(df_airport_state['state_code'], \"'|\\t\")\n",
    "df_airport_state['state_name']=replace_series_value(df_airport_state['state_name'], \"'|\\t\")\n",
    "df_airport_state.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.5.5: Data Exploration and Cleaning (Travelling PUrpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purpose_code</th>\n",
       "      <th>purpose_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purpose_code purpose_name\n",
       "0             1     Business\n",
       "1             2     Pleasure\n",
       "2             3      Student"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_purpose=load_csv('./dataset/i94visa_travelling_purpose.map', separator='=', header=None)\n",
    "df_purpose.columns=['purpose_code','purpose_name']\n",
    "# df_purpose['state_code']=replace_series_value(df_purpose['state_code'], \"'|\\t\")\n",
    "# df_purpose['state_name']=replace_series_value(df_purpose['state_name'], \"'|\\t\")\n",
    "df_purpose.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The tables are broken down into `fact` and `dimension` tables. \n",
    "The database schema make use of the `snowflake schema` design. \n",
    "This design is chosen as it will allows the simplified on the query and faster aggregation.\n",
    "\n",
    "The following are the `fact` table:\n",
    "1. Arrival Summary Table \n",
    "\n",
    "<br/>\n",
    "\n",
    "The following is the `dimension` tables:\n",
    "1. Arrival State Code Table \n",
    "2. Arrival City Code Table \n",
    "3. Arrival Country Code Table \n",
    "4. Season Table \n",
    "5. Temperature Table \n",
    "6. Population Table \n",
    "7. Airport Table \n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "![Data_Schema](./screenshots/database_schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The following are the necessary steps:\n",
    "1. Create the `fact` and `dimension` tables in `PostgreSQL`\n",
    "1. Using `Spark`, load the `194 Immigration` data and perform cleaning and ingesting to `PostgreSQL`\n",
    "2. Using `Pandas`, load the `World Temperature`, `US City Demographic`, `Airport Code` data and perform cleaning and ingesting to `PostgreSQL`\n",
    "3. Once all the data are ingested into their respective tables, run a check on the total count of rows in each table to verify that the data is ingested correctly\n",
    "4. Finally, once all the data are verified, we can run a few queries to check on the quality of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "![Data_Pipeline](./screenshots/data_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_database_connection(database_host, database_name, database_user, database_pass):\n",
    "    conn = psycopg2.connect(f\"host={database_host} dbname={database_name} user={database_user} password={database_pass}\")\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_dataframe_to_tuples(insert_dataframe):\n",
    "    if len(insert_dataframe) == 0:\n",
    "        return (),\"\"\n",
    "    \n",
    "    insert_tuples = [tuple(x) for x in insert_dataframe.values]\n",
    "    insert_columns = ','.join(list(insert_dataframe.columns))\n",
    "    return insert_tuples, insert_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_dataframe_to_database(insert_query, insert_tuples):\n",
    "    total_rows = len(insert_tuples)\n",
    "    print(f\"Executing: {insert_query}\")\n",
    "    print(f\"Executing: Inserting [{total_rows}] rows\")\n",
    "    try:\n",
    "        print(f\"Executing: Connecting to [{DATABASE_NAME}] with {DATABASE_USER}@{DATABASE_HOST}\")\n",
    "        conn = create_database_connection(database_host=DATABASE_HOST, database_name=DATABASE_NAME, database_user=DATABASE_USER, database_pass=DATABASE_PASS)\n",
    "        cur = conn.cursor()\n",
    "        # cur.execute(season_table_insert, df_season_insert.values[0])\n",
    "        cur.executemany(insert_query, insert_tuples)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving dataframe to database: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arrival_summary_table_insert = (\"\"\"\n",
    "INSERT INTO arrival_summary (arrival_month ,arrival_state ,arrival_city ,traveller_citizenship ,\n",
    "    total_travellers ,business_travellers ,leisure_travellers ,student_travellers)\n",
    "                 VALUES (%s, %s, %s, %s, %s, %s, %s, %s);\n",
    "\"\"\")\n",
    "\n",
    "def load_arrival_summary(df_us_travellers):\n",
    "    total_rows = df_us_travellers.count()\n",
    "    if total_rows <= 0:\n",
    "        print(\"Executing: Loading Arrival Summary Fails - dataframe has no data\")\n",
    "        return\n",
    "    \n",
    "    !echo \"Executing: cat ./immigrate_data/*.csv | psql {DATABASE_POSTGRESQL_URL} \\\n",
    "        -c 'COPY arrival_summary(arrival_month, arrival_state, arrival_city, traveller_citizenship, total_travellers ,business_travellers ,leisure_travellers ,student_travellers) from stdin CSV'\"\n",
    "    print(f\"Executing: Inserting [{total_rows}] rows\")\n",
    "    \n",
    "    # rename frame to align with database column names\n",
    "    spark = create_spark_session()\n",
    "    df_us_travellers_renamed = df_us_travellers.filter(col('i94cit').isNotNull())\\\n",
    "                    .select(col('arrival_month').alias('arrival_month'),\n",
    "                                    col('i94addr').alias('arrival_state'),\n",
    "                                    col('i94port').alias('arrival_city'),\n",
    "                                    col('i94cit').cast(IntegerType()).alias('traveller_citizenship'),\n",
    "                                    col('total_travellers').alias('total_travellers'),\n",
    "                                    col('business_travellers').alias('business_travellers'),\n",
    "                                    col('leisure_travellers').alias('leisure_travellers'),\n",
    "                                    col('student_travellers').alias('student_travellers'))\n",
    "    \n",
    "    # output dataframe to csv to be loaded with COPY command\n",
    "    !rm -rfv \"./immigrate_data\"\n",
    "    df_us_travellers_renamed.write.csv(\"immigrate_data\")\n",
    "    \n",
    "    # load csv to postgresql with COPY command\n",
    "    ! echo \"Executing: Connecting to [{DATABASE_NAME}] with {DATABASE_USER}@{DATABASE_HOST}\"\n",
    "    ! cat ./immigrate_data/*.csv | psql \"{DATABASE_POSTGRESQL_URL}\" \\\n",
    "        -c 'COPY arrival_summary(arrival_month, arrival_state, arrival_city, traveller_citizenship, total_travellers ,business_travellers ,leisure_travellers ,student_travellers) from stdin CSV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "season_table_insert = (\"\"\"\n",
    "    INSERT INTO season (season_month, season)\n",
    "                     VALUES (%s, %s)\n",
    "    ON CONFLICT(season_month) \n",
    "    DO update set \n",
    "        season = EXCLUDED.season;\n",
    "    \"\"\")\n",
    "\n",
    "temperature_table_insert = (\"\"\"\n",
    "INSERT INTO temperature (city ,measurement_month ,total_measurements ,min_temperature ,max_temperature ,avg_temperature)\n",
    "                 VALUES (%s, %s, %s, %s, %s, %s)\n",
    "ON CONFLICT(city, measurement_month) \n",
    "DO update set \n",
    "    total_measurements = EXCLUDED.total_measurements,\n",
    "    min_temperature = EXCLUDED.min_temperature,\n",
    "    max_temperature = EXCLUDED.max_temperature,\n",
    "    avg_temperature = EXCLUDED.avg_temperature;\n",
    "\"\"\")\n",
    "\n",
    "def load_season_and_temperature(df_us_temperature):\n",
    "    if len(df_us_temperature) <= 0:\n",
    "        print(\"Executing: Loading Season and Temperature Fails - dataframe has no data\")\n",
    "        return\n",
    "    \n",
    "    df_season_insert = df_us_temperature[['month_name', 'season']].drop_duplicates()\n",
    "    season_tuples, season_columns  = convert_dataframe_to_tuples(df_season_insert)\n",
    "    save_dataframe_to_database(season_table_insert, season_tuples)\n",
    "    \n",
    "    df_temperature_insert = df_us_temperature[['city','month_name', 'total_recordings', 'min_temperature', 'max_temperature', 'avg_temperature']]\n",
    "    temperature_tuples, temperature_columns  = convert_dataframe_to_tuples(df_temperature_insert)\n",
    "    save_dataframe_to_database(temperature_table_insert, temperature_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "population_table_insert = (\"\"\"\n",
    "INSERT INTO population (state ,city ,median_age ,male_population ,female_population ,total_population ,race_diversity)\n",
    "                 VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "ON CONFLICT(state, city) \n",
    "DO update set \n",
    "    median_age = EXCLUDED.median_age,\n",
    "    male_population = EXCLUDED.male_population,\n",
    "    female_population = EXCLUDED.female_population,\n",
    "    total_population = EXCLUDED.total_population,\n",
    "    race_diversity = EXCLUDED.race_diversity;\n",
    "\"\"\")\n",
    "\n",
    "def load_population(df_us_population):\n",
    "    if len(df_us_population) <= 0:\n",
    "        print(\"Executing: Loading Population Fails - dataframe has no data\")\n",
    "        return\n",
    "    \n",
    "    df_population_insert = df_us_population[['state_code', 'city', 'median_age', 'total_male',\n",
    "       'total_female', 'total_population', 'total_race']].drop_duplicates()\n",
    "    population_tuples, population_columns  = convert_dataframe_to_tuples(df_population_insert)\n",
    "    save_dataframe_to_database(population_table_insert, population_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_table_insert = (\"\"\"\n",
    "INSERT INTO airport (airport_id ,gps_code ,iata_code ,local_code ,airport_name ,airport_description ,airport_state ,airport_city ,airport_coordinates_x ,airport_coordinates_y)\n",
    "                 VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "ON CONFLICT(airport_id) \n",
    "DO update set \n",
    "    gps_code = EXCLUDED.gps_code,\n",
    "    iata_code = EXCLUDED.iata_code,\n",
    "    local_code = EXCLUDED.local_code,\n",
    "    airport_name = EXCLUDED.airport_name,\n",
    "    airport_description = EXCLUDED.airport_description,\n",
    "    airport_state = EXCLUDED.airport_state,\n",
    "    airport_city = EXCLUDED.airport_city,\n",
    "    airport_coordinates_x = EXCLUDED.airport_coordinates_x,\n",
    "    airport_coordinates_y = EXCLUDED.airport_coordinates_y;\n",
    "\"\"\")\n",
    "\n",
    "def load_airport(df_us_airport):\n",
    "    if len(df_us_airport) <= 0:\n",
    "        print(\"Executing: Loading Airport Fails - dataframe has no data\")\n",
    "        return\n",
    "    \n",
    "    df_airport_insert = df_us_airport[['id', 'gps_code', 'iata_code', 'local_code',\n",
    "       'name', 'type', 'state', 'city', 'coordinates_x', 'coordinates_y']].drop_duplicates()\n",
    "    airport_tuples, airport_columns  = convert_dataframe_to_tuples(df_airport_insert)\n",
    "    save_dataframe_to_database(airport_table_insert, airport_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arrival_country_table_insert = (\"\"\"\n",
    "INSERT INTO arrival_country_code (country_code, country_name)\n",
    "                 VALUES (%s, %s)\n",
    "ON CONFLICT(country_code) \n",
    "DO update set \n",
    "    country_name = EXCLUDED.country_name;\n",
    "\"\"\")\n",
    "\n",
    "def load_arrival_country(df_arrival_country):\n",
    "    if len(df_arrival_country) <= 0:\n",
    "        print(\"Executing: Loading Arrival Country Fails - dataframe has no data\")\n",
    "        return\n",
    "    \n",
    "    df_arrival_country_insert = df_arrival_country[['country_code', 'country_name']]\n",
    "    arrival_country_tuples, arrival_country_columns  = convert_dataframe_to_tuples(df_arrival_country_insert)\n",
    "    save_dataframe_to_database(arrival_country_table_insert, arrival_country_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arrival_state_table_insert = (\"\"\"\n",
    "INSERT INTO arrival_state_code (state_code, state_name)\n",
    "                 VALUES (%s, %s)\n",
    "ON CONFLICT(state_code) \n",
    "DO update set \n",
    "    state_name = EXCLUDED.state_name;\n",
    "\"\"\")\n",
    "\n",
    "def load_arrival_state(df_arrival_state):\n",
    "    if len(df_arrival_state) <= 0:\n",
    "        print(\"Executing: Loading Arrival State Fails - dataframe has no data\")\n",
    "        return\n",
    "    \n",
    "    df_arrival_state_insert = df_arrival_state[['state_code', 'state_name']]\n",
    "    arrival_state_tuples, arrival_state_columns  = convert_dataframe_to_tuples(df_arrival_state_insert)\n",
    "    save_dataframe_to_database(arrival_state_table_insert, arrival_state_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arrival_city_table_insert = (\"\"\"\n",
    "INSERT INTO arrival_city_code (city_code ,city_name ,state_code)\n",
    "                 VALUES (%s, %s, %s)\n",
    "ON CONFLICT(city_code) \n",
    "DO update set \n",
    "    city_name = EXCLUDED.city_name,\n",
    "    state_code = EXCLUDED.state_code;\n",
    "\"\"\")\n",
    "\n",
    "def load_arrival_city(df_arrival_city):\n",
    "    if len(df_arrival_city) <= 0:\n",
    "        print(\"Executing: Loading Arrival City Fails - dataframe has no data\")\n",
    "        return\n",
    "    \n",
    "    df_arrival_city_insert = df_arrival_city[['city_code', 'city_name', 'state_code']]\n",
    "    arrival_city_tuples, arrival_city_columns  = convert_dataframe_to_tuples(df_arrival_city_insert)\n",
    "    save_dataframe_to_database(arrival_city_table_insert, arrival_city_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.1 Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Connecting to studentdb@127.0.0.1\n",
      "Executing: Dropping Table - DROP table if exists arrival_summary\n",
      "Executing: Dropping Table - DROP table if exists arrival_country_code\n",
      "Executing: Dropping Table - DROP table if exists arrival_state_code\n",
      "Executing: Dropping Table - DROP table if exists arrival_city_code\n",
      "Executing: Dropping Table - DROP table if exists season\n",
      "Executing: Dropping Table - DROP table if exists temperature\n",
      "Executing: Dropping Table - DROP table if exists population\n",
      "Executing: Dropping Table - DROP table if exists airport\n",
      "Executing: Creating Table - \n",
      "    CREATE TABLE IF NOT EXISTS arrival_summary(\n",
      "        arrival_id SERIAL primary key,\n",
      "        arrival_month varchar(45) NOT NULL,\n",
      "        arrival_state varchar(45) NULL,\n",
      "        arrival_city varchar(45) NULL,\n",
      "        traveller_citizenship int NULL,\n",
      "        total_travellers int NULL,\n",
      "        business_travellers int NULL,\n",
      "        leisure_travellers int NULL,\n",
      "        student_travellers int NULL,\n",
      "        UNIQUE(arrival_id)\n",
      "    )\n",
      "\n",
      "Executing: Creating Table - \n",
      "    CREATE TABLE IF NOT EXISTS arrival_country_code(\n",
      "        country_id SERIAL primary key,\n",
      "        country_code integer NOT NULL,\n",
      "        country_name varchar(255) NULL,\n",
      "        UNIQUE(country_id),\n",
      "        UNIQUE(country_code)\n",
      "    )\n",
      "\n",
      "Executing: Creating Table - \n",
      "    CREATE TABLE IF NOT EXISTS arrival_state_code(\n",
      "        state_id SERIAL primary key,\n",
      "        state_code varchar(45) NOT NULL,\n",
      "        state_name varchar(255) NULL,\n",
      "        UNIQUE(state_id),\n",
      "        UNIQUE(state_code)\n",
      "    )\n",
      "\n",
      "Executing: Creating Table - \n",
      "    CREATE TABLE IF NOT EXISTS arrival_city_code(\n",
      "        city_id SERIAL primary key,\n",
      "        city_code varchar(45) NOT NULL,\n",
      "        city_name varchar(255) NULL,\n",
      "        state_code varchar(45) NULL,\n",
      "        UNIQUE(city_id),\n",
      "        UNIQUE(city_code)\n",
      "    )\n",
      "\n",
      "Executing: Creating Table - \n",
      "    CREATE TABLE IF NOT EXISTS season(\n",
      "        season_id SERIAL primary key,\n",
      "        season_month varchar(45) NOT NULL,\n",
      "        season varchar(45) NOT NULL,\n",
      "        UNIQUE(season_id),\n",
      "        UNIQUE(season_month)\n",
      "    )\n",
      "\n",
      "Executing: Creating Table - \n",
      "    CREATE TABLE IF NOT EXISTS temperature(\n",
      "        temperature_id SERIAL primary key,\n",
      "        city varchar(255) NOT NULL,\n",
      "        measurement_month varchar(45) NOT NULL,\n",
      "        total_measurements varchar(45) NULL,\n",
      "        min_temperature decimal NULL,\n",
      "        max_temperature decimal NULL,\n",
      "        avg_temperature decimal NULL,\n",
      "        UNIQUE(temperature_id),\n",
      "        UNIQUE(city, measurement_month)\n",
      "    )\n",
      "\n",
      "Executing: Creating Table - \n",
      "    CREATE TABLE IF NOT EXISTS population(\n",
      "        population_id SERIAL primary key,\n",
      "        state varchar(255) NOT NULL,\n",
      "        city varchar(255) NOT NULL,\n",
      "        median_age decimal NULL,\n",
      "        male_population integer NULL,\n",
      "        female_population integer NULL,\n",
      "        total_population integer NULL,\n",
      "        race_diversity integer NULL,\n",
      "        UNIQUE(population_id),\n",
      "        UNIQUE(state, city)\n",
      "    )\n",
      "\n",
      "Executing: Creating Table - \n",
      "    CREATE TABLE IF NOT EXISTS airport(\n",
      "        airport_id varchar(45) primary key,\n",
      "        gps_code varchar(45) NULL,\n",
      "        iata_code varchar(45) NULL,\n",
      "        local_code varchar(45) NULL,\n",
      "        airport_name varchar(255) NULL,\n",
      "        airport_description varchar(255) NULL,\n",
      "        airport_state varchar(100) NULL,\n",
      "        airport_city varchar(255) NULL,\n",
      "        airport_coordinates_x decimal NULL,\n",
      "        airport_coordinates_y decimal NULL,\n",
      "        UNIQUE(airport_id)\n",
      "    )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 create_tables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.2 Ingest Data Into Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load arrival_summary - df_immigration_agg\n",
    "# load arrival_state_code - df_airport_state\n",
    "# load arrival_city_code - df_airport_city\n",
    "# load arrival_country_code - df_traveller_country\n",
    "# load season - df_us_temp_agg\n",
    "# load temperature - df_us_temp_agg\n",
    "# load population - df_demographic_agg\n",
    "# load airport - df_us_airport_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city_code', 'city_name_with_state', 'city_name', 'state_code'], dtype='object')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_city.columns[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: cat ./immigrate_data/*.csv | psql postgresql://student:student@127.0.0.1:5432/travellers         -c 'COPY arrival_summary(arrival_month, arrival_state, arrival_city, traveller_citizenship, total_travellers ,business_travellers ,leisure_travellers ,student_travellers) from stdin CSV'\n",
      "Executing: Inserting [810989] rows\n",
      "removed './immigrate_data/.part-00002-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00019-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00046-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00010-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00001-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00027-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00017-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00007-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00006-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00009-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00030-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00008-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/_SUCCESS'\n",
      "removed './immigrate_data/.part-00012-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00035-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00000-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00044-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00015-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00020-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00038-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00018-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00041-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00032-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00037-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00018-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00036-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00013-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00028-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00030-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00011-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00031-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00005-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00040-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00028-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00027-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00004-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00022-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00003-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00039-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00004-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00024-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00015-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00019-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00006-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00043-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00035-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00008-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00042-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00029-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00016-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00044-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00031-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00025-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00010-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00012-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00024-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00041-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00003-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00021-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00014-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00029-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00036-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00022-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00042-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00045-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/._SUCCESS.crc'\n",
      "removed './immigrate_data/part-00039-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00020-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00033-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00038-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00007-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00034-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00046-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00000-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00002-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00021-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00026-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00011-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00037-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00014-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00017-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00033-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00032-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00043-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00023-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00026-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00016-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00040-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00009-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00013-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00001-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/part-00025-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed './immigrate_data/.part-00045-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00005-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/.part-00034-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv.crc'\n",
      "removed './immigrate_data/part-00023-cfe74b34-56c7-46f1-a919-a3776c5ad198-c000.csv'\n",
      "removed directory './immigrate_data'\n",
      "Executing: Connecting to [travellers] with student@127.0.0.1\n",
      "COPY 808585\n"
     ]
    }
   ],
   "source": [
    "load_arrival_summary(df_immigration_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: \n",
      "    INSERT INTO season (season_month, season)\n",
      "                     VALUES (%s, %s)\n",
      "    ON CONFLICT(season_month) \n",
      "    DO update set \n",
      "        season = EXCLUDED.season;\n",
      "    \n",
      "Executing: Inserting [12] rows\n",
      "Executing: Connecting to [travellers] with student@127.0.0.1\n",
      "--\n",
      "Executing: \n",
      "INSERT INTO temperature (city ,measurement_month ,total_measurements ,min_temperature ,max_temperature ,avg_temperature)\n",
      "                 VALUES (%s, %s, %s, %s, %s, %s)\n",
      "ON CONFLICT(city, measurement_month) \n",
      "DO update set \n",
      "    total_measurements = EXCLUDED.total_measurements,\n",
      "    min_temperature = EXCLUDED.min_temperature,\n",
      "    max_temperature = EXCLUDED.max_temperature,\n",
      "    avg_temperature = EXCLUDED.avg_temperature;\n",
      "\n",
      "Executing: Inserting [2976] rows\n",
      "Executing: Connecting to [travellers] with student@127.0.0.1\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "load_season_and_temperature(df_us_temp_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: \n",
      "INSERT INTO population (state ,city ,median_age ,male_population ,female_population ,total_population ,race_diversity)\n",
      "                 VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
      "ON CONFLICT(state, city) \n",
      "DO update set \n",
      "    median_age = EXCLUDED.median_age,\n",
      "    male_population = EXCLUDED.male_population,\n",
      "    female_population = EXCLUDED.female_population,\n",
      "    total_population = EXCLUDED.total_population,\n",
      "    race_diversity = EXCLUDED.race_diversity;\n",
      "\n",
      "Executing: Inserting [595] rows\n",
      "Executing: Connecting to [travellers] with student@127.0.0.1\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "load_population(df_demographic_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: \n",
      "INSERT INTO airport (airport_id ,gps_code ,iata_code ,local_code ,airport_name ,airport_description ,airport_state ,airport_city ,airport_coordinates_x ,airport_coordinates_y)\n",
      "                 VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
      "ON CONFLICT(airport_id) \n",
      "DO update set \n",
      "    gps_code = EXCLUDED.gps_code,\n",
      "    iata_code = EXCLUDED.iata_code,\n",
      "    local_code = EXCLUDED.local_code,\n",
      "    airport_name = EXCLUDED.airport_name,\n",
      "    airport_description = EXCLUDED.airport_description,\n",
      "    airport_state = EXCLUDED.airport_state,\n",
      "    airport_city = EXCLUDED.airport_city,\n",
      "    airport_coordinates_x = EXCLUDED.airport_coordinates_x,\n",
      "    airport_coordinates_y = EXCLUDED.airport_coordinates_y;\n",
      "\n",
      "Executing: Inserting [22747] rows\n",
      "Executing: Connecting to [travellers] with student@127.0.0.1\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "load_airport(df_us_airport_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: \n",
      "INSERT INTO arrival_country_code (country_code, country_name)\n",
      "                 VALUES (%s, %s)\n",
      "ON CONFLICT(country_code) \n",
      "DO update set \n",
      "    country_name = EXCLUDED.country_name;\n",
      "\n",
      "Executing: Inserting [289] rows\n",
      "Executing: Connecting to [travellers] with student@127.0.0.1\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "load_arrival_country(df_traveller_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: \n",
      "INSERT INTO arrival_state_code (state_code, state_name)\n",
      "                 VALUES (%s, %s)\n",
      "ON CONFLICT(state_code) \n",
      "DO update set \n",
      "    state_name = EXCLUDED.state_name;\n",
      "\n",
      "Executing: Inserting [55] rows\n",
      "Executing: Connecting to [travellers] with student@127.0.0.1\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "load_arrival_state(df_airport_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: \n",
      "INSERT INTO arrival_city_code (city_code ,city_name ,state_code)\n",
      "                 VALUES (%s, %s, %s)\n",
      "ON CONFLICT(city_code) \n",
      "DO update set \n",
      "    city_name = EXCLUDED.city_name,\n",
      "    state_code = EXCLUDED.state_code;\n",
      "\n",
      "Executing: Inserting [660] rows\n",
      "Executing: Connecting to [travellers] with student@127.0.0.1\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "load_arrival_city(df_airport_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.1 Check Total Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Checking Table - \n",
      "    select count(*) from arrival_summary\n",
      "\n",
      "Executing: found [808585] records\n",
      "--\n",
      "Executing: Checking Table - \n",
      "    select count(*) from arrival_country_code\n",
      "\n",
      "Executing: found [289] records\n",
      "--\n",
      "Executing: Checking Table - \n",
      "    select count(*) from arrival_state_code\n",
      "\n",
      "Executing: found [55] records\n",
      "--\n",
      "Executing: Checking Table - \n",
      "    select count(*) from arrival_city_code\n",
      "\n",
      "Executing: found [660] records\n",
      "--\n",
      "Executing: Checking Table - \n",
      "    select count(*) from season\n",
      "\n",
      "Executing: found [12] records\n",
      "--\n",
      "Executing: Checking Table - \n",
      "    select count(*) from temperature\n",
      "\n",
      "Executing: found [2976] records\n",
      "--\n",
      "Executing: Checking Table - \n",
      "    select count(*) from population\n",
      "\n",
      "Executing: found [595] records\n",
      "--\n",
      "Executing: Checking Table - \n",
      "    select count(*) from airport\n",
      "\n",
      "Executing: found [22747] records\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "!python3 check_tables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary\n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.3.1: Arrival Summary Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The `Arrival Summary` tables consists of information about the type of visitors to the country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Name | Description | Type |\n",
    "| --- | --- | --- |\n",
    "| arrival_id  | auto increment key | integer |\n",
    "| arrival_month   | month that the travellers arrived | varchar |\n",
    "| arrival_state   | state that the travellers arrived | varchar |\n",
    "| arrival_city   | city that the travellers arrived | varchar |\n",
    "| traveller_citizenship   | country where the travellers are citizen of | integer |\n",
    "| total_travellers   | total travellers for the month | integer |\n",
    "| business_travellers   | total travellers for the month visiting for business | integer |\n",
    "| leisure_travellers   | total travellers for the month visiting for leisure | integer |\n",
    "| student_travellers   | total travellers for the month visiting for study | integer |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.3.2: Arrival Country Code Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The `Arrival Country Code` tables consists of information about the country code and its corresponding country name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Name | Description | Type |\n",
    "| --- | --- | --- |\n",
    "| country_id  | auto increment key | integer |\n",
    "| country_code   | code representation for the country | integer  |\n",
    "| country_name   | name of the country | varchar |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.3.3: Arrival State Code Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The `Arrival State Code` tables consists of information about the state code and its corresponding state name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Name | Description | Type |\n",
    "| --- | --- | --- |\n",
    "| state_id  | auto increment key | integer |\n",
    "| state_code   | code representation for the state | varchar |\n",
    "| state_name   | name of the state | varchar |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.3.4: Arrival City Code Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The `Arrival City Code` tables consists of information about the city code and its corresponding city name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Name | Description | Type |\n",
    "| --- | --- | --- |\n",
    "| city_id  | auto increment key | integer |\n",
    "| city_code   | code representation for the city | varchar |\n",
    "| city_name   | name of the city | varchar |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.3.5: Season Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The `Season` table consists of information about the season of the respective months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Name | Description | Type |\n",
    "| --- | --- | --- |\n",
    "| season_id  | auto increment key | integer |\n",
    "| season_month   | month of the season | varchar |\n",
    "| season   | the season of the month | varchar |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.3.6: Temperature Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The `Temperature` table consists of information regarding the temperature measured across the years for the respective cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Name | Description | Type |\n",
    "| --- | --- | --- |\n",
    "| temperature_id  | auto increment key | integer |\n",
    "| city | city that the temperature was taken | varchar |\n",
    "| measurement_month | month that the temperature was taken | varchar |\n",
    "| total_measurements | total number of temperature recordings that have taken for the month over the years | varchar |\n",
    "| min_temperature | minimum temperature recorded for the city | decimal |\n",
    "| max_temperature | maximum temperature recorded for the city | decimal |\n",
    "| avg_temperature | average temperature recorded for the city | decimal |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.3.7: Population Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The `Population` table consists of information regarding the total number of people residing in the respective cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Name | Description | Type |\n",
    "| --- | --- | --- |\n",
    "| population_id  | auto increment key | integer |\n",
    "| state | state that the population belongs to | varchar |\n",
    "| city | city that the population belongs to | varchar |\n",
    "| median_age | median age of the city | decimal |\n",
    "| male_population | total males in the city | integer |\n",
    "| female_population | total females in the city | integer |\n",
    "| total_population | total population in the city | integer |\n",
    "| race_diversity | different type of race in the city | integer |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.3.8: Airport Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The `Airport` table consists of information regarding the airports around US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Name | Description | Type |\n",
    "| --- | --- | --- |\n",
    "| airport_id | identifier to identify the airport | varchar |\n",
    "| gps_code | gps code repesentation for the airport | varchar |\n",
    "| iata_code | iata code repesentation for the airport | varchar |\n",
    "| local_code | local code repesentation for the airport | varchar |\n",
    "| airport_name | name of the airport | varchar |\n",
    "| airport_description | type of airport | varchar |\n",
    "| airport_state | state which the airport is situated | varchar |\n",
    "| airport_city | city which the airport is situated | varchar |\n",
    "| airport_coordinates_x | coordinates which the airport is situated | decimal |\n",
    "| airport_coordinates_y | coordinates which the airport is situated | decimal |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.4 Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.4.1: Use Case #1 - Top 5 Countries Visitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Find the 5 countries, where its citizen frequent visit US in 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Selecting #1 - \n",
      "USE CASE 1: Find the Top 5 Countries Who Most Frequented US in 2016\n",
      "\n",
      "Executing: Selecting #1 - \n",
      "select s.traveller_citizenship, c.country_name, sum(s.total_travellers) as yearly_travellers\n",
      "from arrival_summary s\n",
      "    left join arrival_country_code c on s.traveller_citizenship = c.country_code\n",
      "group by s.traveller_citizenship, c.country_name\n",
      "order by yearly_travellers desc\n",
      "limit 5;\n",
      "\n",
      "Executing: found [5] records\n",
      "(135, 'UNITED KINGDOM', 4531534)\n",
      "(209, 'JAPAN', 3278033)\n",
      "(245, 'CHINA, PRC', 3128257)\n",
      "(582, 'MEXICO Air Sea, and Not Reported (I-94, no land arrivals)', 2617070)\n",
      "(148, None, 2051390)\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "!python3 select_queries.py -c 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.4.2: Use Case #2 - Top 5 Cities Attraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Find the 5 cities, where travellers frequent visited in 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Selecting #2 - \n",
      "USE CASE 2: Find the Top 5 Cities That Are Most Visited in 2016\n",
      "\n",
      "Executing: Selecting #2 - \n",
      "select s.arrival_city, cc.city_name, cc.state_code, \n",
      "    sc.state_name, sum(s.total_travellers) as yearly_travellers\n",
      "from arrival_summary s\n",
      "    left join arrival_city_code cc on s.arrival_city = cc.city_code\n",
      "    left join arrival_state_code sc on trim(sc.state_code) = trim(cc.state_code)\n",
      "group by  s.arrival_city, cc.city_name, cc.state_code, \n",
      "    sc.state_name\n",
      "order by yearly_travellers desc\n",
      "limit 5\n",
      "\n",
      "Executing: found [5] records\n",
      "('NYC', 'NEW YORK', ' NY', 'NEW YORK', 6671232)\n",
      "('MIA', 'MIAMI', ' FL', 'FLORIDA', 5121183)\n",
      "('LOS', 'LOS ANGELES', ' CA', 'CALIFORNIA', 4598326)\n",
      "('SFR', 'SAN FRANCISCO', ' CA', 'CALIFORNIA', 2308671)\n",
      "('HHW', 'HONOLULU', ' HI', 'HAWAII', 2248751)\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "!python3 select_queries.py -c 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.4.3: Use Case #3 - Relationship of Season and Travelling Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Study if there is any relationship between the various season and travelling purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Selecting #3 - \n",
      "USE CASE 3: Study the relationship between season and the different types of travellers\n",
      "\n",
      "Executing: Selecting #3 - \n",
      "select a.arrival_month, s.season,\n",
      "\tsum(a.total_travellers) as total_travellers,\n",
      "\tsum(a.business_travellers) as business_travellers,\n",
      "\tsum(a.leisure_travellers) as leisure_travellers,\n",
      "\tsum(a.student_travellers) as student_travellers\n",
      "from arrival_summary a\n",
      "\tleft join season s on  a.arrival_month = s.season_month\n",
      "group by a.arrival_month, s.season\n",
      "order by EXTRACT(MONTH FROM to_date(a.arrival_month, 'Month'))\n",
      "\n",
      "Executing: found [12] records\n",
      "('January', 'winter', 2847924, 522890, 1939899, 385135)\n",
      "('February', 'winter', 2570543, 446667, 2077101, 46775)\n",
      "('March', 'winter', 3157072, 446208, 2607405, 103459)\n",
      "('April', 'spring', 3096313, 522079, 2530868, 43366)\n",
      "('May', 'spring', 3444249, 530473, 2858037, 55739)\n",
      "('June', 'spring', 3574469, 487098, 3009651, 77720)\n",
      "('July', 'summer', 4261837, 415603, 3728464, 117770)\n",
      "('August', 'summer', 4097428, 375838, 3281579, 440011)\n",
      "('September', 'summer', 3717134, 514552, 3070324, 132258)\n",
      "('October', 'fall', 3648776, 578568, 3029753, 40455)\n",
      "('November', 'fall', 2914188, 481905, 2380748, 51535)\n",
      "('December', 'fall', 3432021, 249753, 3104816, 77452)\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "!python3 select_queries.py -c 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.1: Tools and Technologies Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The following are the tools/libraries that will be used: <br />\n",
    "1) Pandas \n",
    "\n",
    "> `Pandas` will be use to load the `World Temperature Data`, \n",
    "`US City Demographic Data`, `Airport Code Data`. In order to use `Pandas`, please ensure `pip` is installed and that the `pandas` library is installed via `pip`\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "2) Spark \n",
    "\n",
    "> `Spark` will be use to load the `194 Immigration Data`, which is in parquet format and is in millions of rows. In order to run `Spark`, please ensure that spark cluster is either installed or the standalone mode is setup.\n",
    "<br/><br/>\n",
    "\n",
    "3) PostgreSQL\n",
    "\n",
    "> `PostgreSQL` will be use to store the proceessed data for future analysis. In order to run `PostgreSQL`, please ensure the the postgresql database is installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.2: How often should the data be updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "1) `arrival_summary` table update frequency (monthly)\n",
    "\n",
    "> As the data are usually used for analytics purposes and the `arrival_summary` table consists of monthly travellers information, we can update the table monthly.\n",
    "\n",
    "2) `arrival_*` related table update frequency (yearly)\n",
    "\n",
    "> As for the rest of the arrival-related tables such as `arrival_country_code`,`arrival_state_code`, `arrival_city_code`, the information is more static and can be maintained yearly to add in any new changes\n",
    "\n",
    "3) `season` and `temperature` table update frequency (monthly/yearly)\n",
    "\n",
    "> As the weather data is recorded monthly, hence the information can be maintained either monthly or yearly to add in the new changes\n",
    "\n",
    "4) `population` table (adhoc)\n",
    "\n",
    "> As the population data is not readily available, the information can only be maintained if the relevant organisation disclosed the information\n",
    "\n",
    "5) `airport` table update frequency (yearly) \n",
    "\n",
    "> As the airport data is relatively static, it can be maintained yearly to add in any new changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5.3: Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.3.1: Scenario 1 - The data was increased by 100x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    ">The data amount will surmount to big data (one million x 100 = hundred million). Assuming the data stored in any storage is approximately 1kb, hundred million will means that the storage alone would require almost close to 100 TB (hundred million * 1kb) of storage space, which is impossible to store in just 1 machine.\n",
    "<br /><br />\n",
    "We will need to be running spark to process the data and ingesting it into our storage as the standard notebook would not be able to handle such a large amount of data either due to the limitation of its memory or its storage. By leveraging on spark, we not only able to break down the big tasks into smaller tasks which are doable in most compute, but also allows the data to be stored in a distributed manner, thus allowing higher availablilty (if one machine storing the data crashed, there is another one that have a copy) through replication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.3.2: Scenario 2 - The data populates a dashboard that must be updated on a daily basis by 7am every day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    ">We can use airflow and configure a airflow job which will run at 7am every day to update the data required for the dashboard. In addition, we can redirect any fail job to any notifications so that we would know that the update job need to be retrigger manually and that there might be some reason that the update could not complete automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.3.3: Scenario 3 - The database needed to be accessed by 100+ people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    ">We will probably need to have a load balancer to cater to the 100+ people so that our service would not be overwhelm. Alternatively if the data are static and don't change much, we can consider introducing a caching mechanism so that the result can be quickly return to the user.\n",
    "<br /><br />\n",
    "Another point to note is that if the data is not sensitive, we might also want to consider using cloud services such as AWS Elastic Load Balancer, which have an auto scaling feature that would be handy depending on the number of concurrent calls. That way, we won't have to worry about the user overwhelming the services, which retrieve the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 6: Housekeep Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Delete all the tables that were created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "!python3 drop_tables.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
